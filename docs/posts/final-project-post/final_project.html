<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Manuel Fors, Liam Smith, Yide (Alex) Xu">
<meta name="dcterms.date" content="2024-05-17">
<meta name="description" content="Predicting Population Density with Land Cover">

<title>My Awesome CSCI 0451 Blog - Project Blog Post</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>

      .quarto-title-block .quarto-title-banner h1,
      .quarto-title-block .quarto-title-banner h2,
      .quarto-title-block .quarto-title-banner h3,
      .quarto-title-block .quarto-title-banner h4,
      .quarto-title-block .quarto-title-banner h5,
      .quarto-title-block .quarto-title-banner h6
      {
        color: white;
      }

      .quarto-title-block .quarto-title-banner {
        color: white;
background-image: url(../../img/landscape.png);
background-size: cover;
      }
</style>
<script src="../../site_libs/quarto-diagram/mermaid.min.js"></script>
<script src="../../site_libs/quarto-diagram/mermaid-init.js"></script>
<link href="../../site_libs/quarto-diagram/mermaid.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">My Awesome CSCI 0451 Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/manuel-fors/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Project Blog Post</h1>
                  <div>
        <div class="description">
          Predicting Population Density with Land Cover
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">csci415</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Manuel Fors, Liam Smith, Yide (Alex) Xu </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">May 17, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="predicting-population-density-using-landcover-data" class="level1">
<h1>Predicting Population Density Using Landcover Data</h1>
<section id="by-manny-fors-liam-smith-alex-xu" class="level5">
<h5 class="anchored" data-anchor-id="by-manny-fors-liam-smith-alex-xu">By: Manny Fors, Liam Smith, Alex Xu</h5>
</section>
<section id="abstract" class="level2">
<h2 class="anchored" data-anchor-id="abstract">Abstract</h2>
<p>Our project takes on the challenge of predicting population density in regions lacking data. Leveraging landcover image data and tract geometry, our approach involves computing zonal statistics and employing machine learning models. With this problem in mind, we employ satellite data from Connecticut due to its completeness and its potential to also be applied to other Northeastern States within the US. We create Linear Regression models and Spatial Autoregression models with our zonal statistics and tract data. We gauge their efficacy based on their mean-squared error and <span class="math inline">\(R^2\)</span> value. Through this, we find that Linear Regression with No Penalty works best out of our Linear Regression models and our Endogenous Spatial Autoregression model works better than the Exogenous model. Furthermore, we conclude that Spatial Autoregression is more effective at predicting population density than Linear Regression. In regions without adequate census data, the Exogenous model would improve estimations of population density by taking into account the landcover of a given region and its neighbors. Our code and datasets are available through our <a href="https://github.com/Liam-W-Smith/csci-0451-final-project/tree/main">Github</a></p>
</section>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>In countries such as the US, there is a large and accurate amount of census data. However there are many ountries in areas where the resources for gathering census data is <a href="https://nigeria.iom.int/news/npc-we-lack-accurate-figures-nigerias-population">lesser</a>. This is potentially due to geographic inaccessibility, political conflict, administrative failiure, and as mentioned previously, a lack of resources. <strong>Thus, we want a way to predict human populations around the world with the data of the land itself, satellite imagery</strong>. With this imaging, the geography is divided into classes which we can then use as variables for our model. Research into this topic has stagnated to a degree, however <span class="citation" data-cites="tian2005modeling">Tian et al. (<a href="#ref-tian2005modeling" role="doc-biblioref">2005</a>)</span> produced a hallmark paper which tested the effectivity of modeling population with land cover data. It found that a similar model could have “feasible” and can have “high accuracy”. They utilized Linear Regression, and also manually broke down China into even 1km by 1km cells. Because of availablity of census data, we instead used census tracts, but we continued with the idea of utilizing Linear Regression. With some exploratory graphs of Connecticut, we discovered there might be a Spatial Pattern within our data. In order to take this into account during modeling, we started researching into machine learning algorithms with a spatial component. We came across a paper by <span class="citation" data-cites="liu2022incorporating">Liu, Kounadi, and Zurita-Milla (<a href="#ref-liu2022incorporating" role="doc-biblioref">2022</a>)</span>, which concluded that models with a spatial component, such as spatial lag, garner better results than those without. They used spatial lag, and eigvenvectors spatial filtering to predict things beyond our datasets such as soil types. Thus, we sought to create Linear Regression Models and Spatial Autoregressive models, and compare the them to see which is more effective in predicting population density based on land cover.</p>
</section>
<section id="values-statement" class="level2">
<h2 class="anchored" data-anchor-id="values-statement">Values Statement</h2>
<p>NASA in a webinar session called “Humanitarian Applications Using NASA Earth Observations” presented how satellite remote-sensing data could be useful in monitoring humanitarian conditions at refugee settlements. Human settlements could be detected through remote sensing images and therefore could be used to predict the population in a region. This talk alerted us that we still lack necessary population data in many parts of the world, but also demonstrated how remote sensing could be a powerful tool in tackling this problem and solving lack of population data in different countries. Thus, we decide to investigate the connection between remote sensing land cover data and population density in a context with better data coverage.</p>
<p>This type of model would be most beneficial by governments and government organizations. These users would most likely be hospital contractors, policy makers, emergency services providers such as ambulances and firefighers, and sociologists. Population census data is crucial for policy makers as it assists in city management so that the equitable distribution of resources can be better calculated.</p>
<p>The implications extend beyond helping users. Real people would be affected by this technology. Those who are workers in fields such as emergency service work, or school teachers who might have been over-worked previously may be relieved by the building of new hospitals and schools to compensate for population changes. However, the negative effects are also extremely real.</p>
<p>Imagining that this model expanded beyond the barriers of Connecticut and is being used in countries with much lower census data such as Brazil, there might be a calculation for a forestry company to continue harvesting wood from the Amazon, but they do not want to affect populations. Our algorithm calculates there are very few people in the area, as there is very dense land cover in the Amazon. This company starts to cut down trees and discovers that they are in an area of Indigenous peoples. A minority group that is already negatively affected continues to be disenfranchised. The issue of undercalculating the population density in an area can also affect the amount of resources a policymaker might provide to a region with a much greater population and lacking resources. This would also continue to negatively impact an already negatively impacted area.</p>
<p>Ultimately, the world would be a more equitable and sustainable place if this type of technology could assist countries lacking population data. The positive aspects of providing data where there is none provides the potential for great resource partioning, and better understanding of a countries population.</p>
</section>
<section id="materials-and-methods" class="level2">
<h2 class="anchored" data-anchor-id="materials-and-methods">Materials and Methods</h2>
<section id="necessary-data" class="level3">
<h3 class="anchored" data-anchor-id="necessary-data">Necessary Data</h3>
<p>With this project being the entire state of Connecticut, we utilized landcover data, population, shape files for graphing, and synthesized data which combined our various data sets into manageable datasets suitable for modeling.</p>
<p>The bread and butter of our data stems from a 1-meter resolution landcover imagery covering the entire state of Connecticut. Derived from NAIP, the data has already been processed such that every pixel represents a certain class of landcover.</p>
<p>At over 800 MB, the dataset is too large to share via GitHub, and is downloadable by clicking on the first option at <a href="https://coastalimagery.blob.core.windows.net/ccap-landcover/CCAP_bulk_download/High_Resolution_Land_Cover/Phase_2_Expanded_Categories/Legacy_Land_Cover_pre_2024/CONUS/index.html">this link</a>. This landcover dataset was one of the most complete datsets we could find, which is why we wanted to use it for our modelling.</p>
<p>Our other data sources are the geometries and population data on the Census tract level for the state of Connecticut. We downloaded tract geometries directly into our Jupyter Notebook <strong>final_project.ipynb</strong> using the Pygris package, and we downloaded the population data from Social Explorer, storing it at <strong>data/population.csv</strong>.</p>
</section>
<section id="methods" class="level3">
<h3 class="anchored" data-anchor-id="methods">Methods</h3>
<p>First, we clean and prepare our data for the model. We start by combining our Tract Geometry of CT with the Population Data of CT to form a new dataset. We utilize both the CT Landcover Data and the Tracts Data in a calculation of Zonal Statistics. This means we calculate the proportion of pixels within each tract that are of a given landcover class. This then is saved as a combined dataset which we then continue to clean by imputing values, performing more advanced Zonal Statistics, and dropping any NA Columns. From there, we are left with data ready to be used in a model.</p>
<p>The flowchart below more elegantly outlines this process</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart LR
  A(Population Data) --&gt; B(Tracts Data)
  C(Tracts Geometry Data) --&gt; B(Tracts Data)
  B --&gt; D{Zonal Statistics}
  E(CT Landcover Data) --&gt; D{Zonal Statistics}
  D{Zonal Statistics} --&gt; F(Combined Data)
  F(Combined Data) --&gt; |Impute Data| G[Ready for Model]
  F --&gt; |Additional Landcover Statistics| G[Ready for Model]
  F --&gt; |Drop Uncommon Landcover| G[Cleaned Data]
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>We then implement three types of Linear Regression:</p>
<ul>
<li><p>Linear Regression with No Penalty Term</p></li>
<li><p>Linear Regression with <span class="math inline">\(\ell_1\)</span> Regularization (Lasso Regression)</p></li>
<li><p>Linear Regression with <span class="math inline">\(\ell_1\)</span> Regularization (Ridge Regression)</p></li>
</ul>
<p>By utilizing the <span class="math inline">\(R^2\)</span> and Mean Squared Error, we quantified the success of each of our models against one another as well as comparing them to <code>sci-kit learn</code>’s own implementations of each of these Linear Regression Models.</p>
<p>Following Linear Regression, we then wanted to implement two types of Spatial AutoRegression:</p>
<ul>
<li><p>Endogenous Spatial Autoregression</p></li>
<li><p>Exogenous Spatial Autoregression</p></li>
</ul>
<p>As our data can be plotted on a map of Connecticut, we felt it would be amiss to not explore Spatial Autogression. Through this style of model, we can take into account the spatial aspect of each tract when we are predicting. We chose both Endogenous and Exogenous Models. Endogenous Models take into account the neighboring tract population densities of a given tract. Exogenous Models take into account the zonal statistics of a given tract’s neighbors.</p>
<p>We merge our data with shape file and calculate the spatial lag of a each tract’s neighbors. The spatial lag is this case is the average population density of a given tracts of land. We also calculate the average landcover types of a given’s tracts neighbors.</p>
<p>In total, we create 8 models which we compare in order to determine the best way to predict population density with landcover data</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart 
A[Cleaned Data] --&gt; B{No Penalty LR}
A --&gt; C{Lasso LR}
B --&gt; K{ours}
B --&gt; L{sci-kit learn}
C --&gt; G{ours}
C --&gt; H{sci-kit learn}
A --&gt; D{Ridge LR}
D --&gt; I{ours}
D --&gt; J{sci-kit learn}
A --&gt; |Spatial Lag Pop Density| E{Endogenous}
A --&gt; |Spatial Lag Landcover| F{Exogenous}

</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="data-preparation" class="level1">
<h1>Data Preparation</h1>
<p>First we import our necessary libraries.</p>
<div id="cell-9" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>script echo skipping <span class="co"># Comment this line out if you want to install these packages</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip install pygris</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip install folium</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip install rasterio</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip install rasterstats</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip install libpysal</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip install geopandas</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>skipping # Comment this line out if you want to install these packages</code></pre>
</div>
</div>
<div id="cell-10" class="cell" data-metadata="{}" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load packages</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>load_ext autoreload</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>autoreload <span class="dv">2</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pygris</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pygris <span class="im">import</span> tracts</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pyplot <span class="im">as</span> plt</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib.colors <span class="im">import</span> TwoSlopeNorm</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib.colors <span class="im">import</span> LinearSegmentedColormap, Normalize</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib.patches <span class="im">import</span> Patch</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> folium</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> linear_regression <span class="im">import</span> LinearRegress, GradientDescentOptimizer</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> rasterstats <span class="im">import</span> zonal_stats</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> rasterio</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression, Ridge, Lasso</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split, cross_val_score</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> r2_score, mean_squared_error, make_scorer</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> libpysal <span class="im">as</span> lp</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> geopandas <span class="im">as</span> gpd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="acquire-tract-geometries" class="level2">
<h2 class="anchored" data-anchor-id="acquire-tract-geometries">Acquire Tract Geometries</h2>
<p>As a test of concept, lets utilize the pygris library to access the CT tracts information and then let’s do a simple plot to ensure it’s correct.</p>
<div id="cell-12" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Download geometry</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>ct_tracts <span class="op">=</span> tracts(state <span class="op">=</span> <span class="st">"CT"</span>, cb <span class="op">=</span> <span class="va">True</span>, cache <span class="op">=</span> <span class="va">True</span>, year <span class="op">=</span> <span class="dv">2016</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Display geometry</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>ct_tracts.plot(ax <span class="op">=</span> ax)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Tracts Cartographic Boundaries"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Using FIPS code '09' for input 'CT'</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="final_project_files/figure-html/cell-4-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="calculate-population-density" class="level2">
<h2 class="anchored" data-anchor-id="calculate-population-density">Calculate Population Density</h2>
<p>Before we begin our journey into zonal statistics and eventually creating a predictive model, we first want to understand what the population density looks like in Connecticut. We have some general hypotheses that the areas around New Haven and Hartford are going to have higher amounts of population, and we also expect to see some small pockets of communities around Connecticut.</p>
<div id="cell-14" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import tracts population data</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>pop <span class="op">=</span> pd.read_csv(<span class="st">"../data/population.csv"</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert data type so join key matches</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>ct_tracts[<span class="st">"Geo_TRACT"</span>] <span class="op">=</span> ct_tracts[<span class="st">"TRACTCE"</span>].astype(<span class="bu">int</span>)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Join attributes to geometry</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>tracts <span class="op">=</span> ct_tracts.merge(pop, how <span class="op">=</span> <span class="st">"inner"</span>, on<span class="op">=</span><span class="st">'Geo_TRACT'</span>)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Project tracts</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>tracts <span class="op">=</span> tracts.to_crs(<span class="st">"EPSG:3857"</span>)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate area in KM^2</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>tracts[<span class="st">"Area"</span>] <span class="op">=</span> tracts.area<span class="op">/</span><span class="dv">1000</span><span class="op">**</span><span class="dv">2</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate population density</span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>tracts[<span class="st">"PopDensity"</span>] <span class="op">=</span> tracts[<span class="st">"SE_A00001_001"</span>]<span class="op">/</span>tracts[<span class="st">"Area"</span>]</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Create map</span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>tracts.plot(<span class="st">"PopDensity"</span>, legend <span class="op">=</span> <span class="va">True</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="final_project_files/figure-html/cell-5-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="intro-to-zonal-statistics" class="level1">
<h1>Intro to Zonal Statistics</h1>
<p>We are going to do quite a bit here which is being abstracted away by the <a href="https://pypi.org/project/rasterio/"><code>rasterio</code></a> package. First and foremost, we are going to load in our landcover data from <a href="https://www.ncei.noaa.gov/products/satellite/gridded-goes-conus">CONUS</a> which is created from satellite date of the Continental United States.</p>
<p>This data comes in the form of a <code>.tif</code> file which is a filetype used for storing geographic satellite data.</p>
<p>The goal of zonal statistics here is relatively straightforward, we are going to do some math that involves the pixels in a given geographic satellite image. Each pixel has an associated number which itself is associated with a key. Each pixel is contained in a “tract” which is a measurement of land by the US Census. We perform mathematics like finding the mean type of pixel in a given area, the max, the minimum, etc. This arithmetic is handled by the <a href="https://pythonhosted.org/rasterstats/"><code>rasterstats</code></a> package.</p>
<section id="first-steps" class="level2">
<h2 class="anchored" data-anchor-id="first-steps">First steps</h2>
<p>Here we open our path to our file, and more importantly, we set up our data to be used in zonal statistics. <code>.read</code> turns our data into a Numpy Array. Following this we are going to <code>.transform</code> our data, which means we are going to take the pixel locations of our coordinates (row col) and map them to our spatial coordinates (x, y). These coordinate values are relative to the <a href="https://www.ncei.noaa.gov/products/satellite/gridded-goes-conus">CRS</a> (Coordinate Reference System) which we defined earlier as <strong>“EPSG:2234”</strong></p>
<div id="cell-17" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>script echo skipping</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="co">#the data can be accessed from https://coastalimagery.blob.core.windows.net/ccap-landcover/CCAP_bulk_download/High_Resolution_Land_Cover/Phase_2_Expanded_Categories/Legacy_Land_Cover_pre_2024/CONUS/ct_2016_ccap_hires_landcover_20200915.zip</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>raster_path <span class="op">=</span> <span class="st">'../data/ct_2016_ccap_hires_landcover_20200915.tif'</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>landcover <span class="op">=</span> rasterio.<span class="bu">open</span>(raster_path)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>arr <span class="op">=</span> landcover.read(<span class="dv">1</span>)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>affine <span class="op">=</span> landcover.transform</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>skipping</code></pre>
</div>
</div>
</section>
<section id="performing-zonal-statistics" class="level2">
<h2 class="anchored" data-anchor-id="performing-zonal-statistics">Performing Zonal statistics</h2>
<p>It’s as simple as importing rasterstats. We have handled the important data manipulation, and now it’s basically plug and play! One function to note is <code>.to_crs</code> which takes in given coordinate reference system and transforms all the points in our dataframe to match that system.</p>
<p>The <code>rasterstats</code> library is very good at getting information from rasters, and we can in fact gain more information by using <code>categorical = True</code>. This allows to see the amount of each type of pixel at a given tract.</p>
<div id="cell-19" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>script echo skipping</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>df_new <span class="op">=</span> zonal_stats(zone, arr, affine<span class="op">=</span>affine, categorical <span class="op">=</span> <span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>skipping</code></pre>
</div>
</div>
<p>Taking a look at our dataframe, we can confirm that each column is a type of pixel and each row is a tract</p>
<div id="cell-21" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>script echo skipping</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>df_categorical <span class="op">=</span> pd.DataFrame(df_new)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>df_categorical</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>skipping</code></pre>
</div>
</div>
</section>
<section id="visualizing-zonal-stats" class="level2">
<h2 class="anchored" data-anchor-id="visualizing-zonal-stats">Visualizing Zonal Stats</h2>
<p>Now that we have information on the amount of each pixel at a given tract, we can find the most common pixel per tract by using the function <code>.idxmax()</code> which will through each row and find the column with the largest value.</p>
<div id="cell-23" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>script echo skipping</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>df_categorical[<span class="st">'max_type'</span>] <span class="op">=</span> df_categorical.idxmax(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>combined_df <span class="op">=</span> pd.concat([tracts, df_categorical], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>combined_df[<span class="st">'max_type'</span>] <span class="op">=</span> combined_df[<span class="st">'max_type'</span>].astype(<span class="bu">str</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>skipping</code></pre>
</div>
</div>
<div id="cell-24" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>script echo skipping</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>combined_df.plot(<span class="st">"max_type"</span>, legend <span class="op">=</span> <span class="va">True</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>skipping</code></pre>
</div>
</div>
<section id="saving-this-data" class="level3">
<h3 class="anchored" data-anchor-id="saving-this-data">Saving this data</h3>
<p>These statistics took quite a while to run, and it may be beneficial to save this data as a csv to continue running statistics in the future</p>
<div id="cell-26" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>script echo skipping</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>combined_df.to_csv(<span class="st">'../data/combined_data.csv'</span>, index<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>skipping</code></pre>
</div>
</div>
</section>
</section>
</section>
<section id="linear-regression" class="level1">
<h1>Linear Regression</h1>
<section id="data-preparation-1" class="level2">
<h2 class="anchored" data-anchor-id="data-preparation-1">Data Preparation</h2>
<p>First, we import our data.</p>
<div id="cell-28" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import and display data</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.read_csv(<span class="st">"../data/combined_data.csv"</span>)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>data.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">STATEFP</th>
<th data-quarto-table-cell-role="th">COUNTYFP</th>
<th data-quarto-table-cell-role="th">TRACTCE</th>
<th data-quarto-table-cell-role="th">AFFGEOID</th>
<th data-quarto-table-cell-role="th">GEOID</th>
<th data-quarto-table-cell-role="th">NAME</th>
<th data-quarto-table-cell-role="th">LSAD</th>
<th data-quarto-table-cell-role="th">ALAND</th>
<th data-quarto-table-cell-role="th">AWATER</th>
<th data-quarto-table-cell-role="th">geometry</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">18</th>
<th data-quarto-table-cell-role="th">19</th>
<th data-quarto-table-cell-role="th">20</th>
<th data-quarto-table-cell-role="th">21</th>
<th data-quarto-table-cell-role="th">22</th>
<th data-quarto-table-cell-role="th">7</th>
<th data-quarto-table-cell-role="th">6</th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">23</th>
<th data-quarto-table-cell-role="th">max_type</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>9</td>
<td>1</td>
<td>11000</td>
<td>1400000US09001011000</td>
<td>9001011000</td>
<td>110.0</td>
<td>CT</td>
<td>4473567</td>
<td>3841130</td>
<td>POLYGON ((-8191739.173321358 5013468.769836016...</td>
<td>...</td>
<td>136572.0</td>
<td>423692.0</td>
<td>142589.0</td>
<td>1378858.0</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>9</td>
<td>1</td>
<td>20800</td>
<td>1400000US09001020800</td>
<td>9001020800</td>
<td>208.0</td>
<td>CT</td>
<td>2315472</td>
<td>0</td>
<td>POLYGON ((-8187432.3302968815 5025136.84023609...</td>
<td>...</td>
<td>NaN</td>
<td>NaN</td>
<td>27939.0</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>11</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>9</td>
<td>1</td>
<td>21400</td>
<td>1400000US09001021400</td>
<td>9001021400</td>
<td>214.0</td>
<td>CT</td>
<td>1640443</td>
<td>0</td>
<td>POLYGON ((-8189589.702028457 5021116.993618919...</td>
<td>...</td>
<td>NaN</td>
<td>NaN</td>
<td>13728.0</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>9</td>
<td>1</td>
<td>22200</td>
<td>1400000US09001022200</td>
<td>9001022200</td>
<td>222.0</td>
<td>CT</td>
<td>1442382</td>
<td>117063</td>
<td>POLYGON ((-8186995.178656538 5019223.193891366...</td>
<td>...</td>
<td>NaN</td>
<td>20584.0</td>
<td>80161.0</td>
<td>99956.0</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>2</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>9</td>
<td>1</td>
<td>43100</td>
<td>1400000US09001043100</td>
<td>9001043100</td>
<td>431.0</td>
<td>CT</td>
<td>6652660</td>
<td>58522</td>
<td>POLYGON ((-8178763.436270848 5029936.759394648...</td>
<td>...</td>
<td>NaN</td>
<td>NaN</td>
<td>9940.0</td>
<td>68655.0</td>
<td>486.0</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>11</td>
</tr>
</tbody>
</table>

<p>5 rows × 87 columns</p>
</div>
</div>
</div>
<p>Looks like there is some missing data in tracts that contain no pixels of a certain class. Let’s impute 0 for all <code>NaN</code> values.</p>
<div id="cell-30" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Impute 0 for missing data</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Before imputation, there were"</span>, pd.isnull(data.iloc[:,<span class="dv">68</span>:<span class="op">-</span><span class="dv">1</span>]).<span class="bu">sum</span>().<span class="bu">sum</span>(), <span class="st">"NaN values."</span>)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>data[pd.isnull(data.iloc[:,<span class="dv">68</span>:<span class="op">-</span><span class="dv">1</span>])] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"After imputation, there are"</span>, pd.isnull(data.iloc[:,<span class="dv">68</span>:<span class="op">-</span><span class="dv">1</span>]).<span class="bu">sum</span>().<span class="bu">sum</span>(), <span class="st">"NaN values."</span>)</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>data.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Before imputation, there were 5774 NaN values.
After imputation, there are 0 NaN values.</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="12">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">STATEFP</th>
<th data-quarto-table-cell-role="th">COUNTYFP</th>
<th data-quarto-table-cell-role="th">TRACTCE</th>
<th data-quarto-table-cell-role="th">AFFGEOID</th>
<th data-quarto-table-cell-role="th">GEOID</th>
<th data-quarto-table-cell-role="th">NAME</th>
<th data-quarto-table-cell-role="th">LSAD</th>
<th data-quarto-table-cell-role="th">ALAND</th>
<th data-quarto-table-cell-role="th">AWATER</th>
<th data-quarto-table-cell-role="th">geometry</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">18</th>
<th data-quarto-table-cell-role="th">19</th>
<th data-quarto-table-cell-role="th">20</th>
<th data-quarto-table-cell-role="th">21</th>
<th data-quarto-table-cell-role="th">22</th>
<th data-quarto-table-cell-role="th">7</th>
<th data-quarto-table-cell-role="th">6</th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">23</th>
<th data-quarto-table-cell-role="th">max_type</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>9</td>
<td>1</td>
<td>11000</td>
<td>1400000US09001011000</td>
<td>9001011000</td>
<td>110.0</td>
<td>CT</td>
<td>4473567</td>
<td>3841130</td>
<td>POLYGON ((-8191739.173321358 5013468.769836016...</td>
<td>...</td>
<td>136572.0</td>
<td>423692.0</td>
<td>142589.0</td>
<td>1378858.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>9</td>
<td>1</td>
<td>20800</td>
<td>1400000US09001020800</td>
<td>9001020800</td>
<td>208.0</td>
<td>CT</td>
<td>2315472</td>
<td>0</td>
<td>POLYGON ((-8187432.3302968815 5025136.84023609...</td>
<td>...</td>
<td>0.0</td>
<td>0.0</td>
<td>27939.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>11</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>9</td>
<td>1</td>
<td>21400</td>
<td>1400000US09001021400</td>
<td>9001021400</td>
<td>214.0</td>
<td>CT</td>
<td>1640443</td>
<td>0</td>
<td>POLYGON ((-8189589.702028457 5021116.993618919...</td>
<td>...</td>
<td>0.0</td>
<td>0.0</td>
<td>13728.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>9</td>
<td>1</td>
<td>22200</td>
<td>1400000US09001022200</td>
<td>9001022200</td>
<td>222.0</td>
<td>CT</td>
<td>1442382</td>
<td>117063</td>
<td>POLYGON ((-8186995.178656538 5019223.193891366...</td>
<td>...</td>
<td>0.0</td>
<td>20584.0</td>
<td>80161.0</td>
<td>99956.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>2</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>9</td>
<td>1</td>
<td>43100</td>
<td>1400000US09001043100</td>
<td>9001043100</td>
<td>431.0</td>
<td>CT</td>
<td>6652660</td>
<td>58522</td>
<td>POLYGON ((-8178763.436270848 5029936.759394648...</td>
<td>...</td>
<td>0.0</td>
<td>0.0</td>
<td>9940.0</td>
<td>68655.0</td>
<td>486.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>11</td>
</tr>
</tbody>
</table>

<p>5 rows × 87 columns</p>
</div>
</div>
</div>
<p>Now that we have complete data, we can calculate the proportion of pixels belonging to each class.</p>
<div id="cell-32" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate total number of pixels in each tract</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>data[<span class="st">"sum"</span>] <span class="op">=</span> data.iloc[:,<span class="dv">68</span>:<span class="op">-</span><span class="dv">1</span>].<span class="bu">sum</span>(axis <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate proportion of pixels belonging to each class</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>data.iloc[:,<span class="dv">68</span>:<span class="op">-</span><span class="dv">2</span>] <span class="op">=</span> data.iloc[:,<span class="dv">68</span>:<span class="op">-</span><span class="dv">2</span>].div(data[<span class="st">'sum'</span>], axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="co"># View data</span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>data.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">STATEFP</th>
<th data-quarto-table-cell-role="th">COUNTYFP</th>
<th data-quarto-table-cell-role="th">TRACTCE</th>
<th data-quarto-table-cell-role="th">AFFGEOID</th>
<th data-quarto-table-cell-role="th">GEOID</th>
<th data-quarto-table-cell-role="th">NAME</th>
<th data-quarto-table-cell-role="th">LSAD</th>
<th data-quarto-table-cell-role="th">ALAND</th>
<th data-quarto-table-cell-role="th">AWATER</th>
<th data-quarto-table-cell-role="th">geometry</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">19</th>
<th data-quarto-table-cell-role="th">20</th>
<th data-quarto-table-cell-role="th">21</th>
<th data-quarto-table-cell-role="th">22</th>
<th data-quarto-table-cell-role="th">7</th>
<th data-quarto-table-cell-role="th">6</th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">23</th>
<th data-quarto-table-cell-role="th">max_type</th>
<th data-quarto-table-cell-role="th">sum</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>9</td>
<td>1</td>
<td>11000</td>
<td>1400000US09001011000</td>
<td>9001011000</td>
<td>110.0</td>
<td>CT</td>
<td>4473567</td>
<td>3841130</td>
<td>POLYGON ((-8191739.173321358 5013468.769836016...</td>
<td>...</td>
<td>0.069327</td>
<td>0.023331</td>
<td>0.225616</td>
<td>0.000000</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>2</td>
<td>6111530.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>9</td>
<td>1</td>
<td>20800</td>
<td>1400000US09001020800</td>
<td>9001020800</td>
<td>208.0</td>
<td>CT</td>
<td>2315472</td>
<td>0</td>
<td>POLYGON ((-8187432.3302968815 5025136.84023609...</td>
<td>...</td>
<td>0.000000</td>
<td>0.012054</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>11</td>
<td>2317904.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>9</td>
<td>1</td>
<td>21400</td>
<td>1400000US09001021400</td>
<td>9001021400</td>
<td>214.0</td>
<td>CT</td>
<td>1640443</td>
<td>0</td>
<td>POLYGON ((-8189589.702028457 5021116.993618919...</td>
<td>...</td>
<td>0.000000</td>
<td>0.008350</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>2</td>
<td>1644135.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>9</td>
<td>1</td>
<td>22200</td>
<td>1400000US09001022200</td>
<td>9001022200</td>
<td>222.0</td>
<td>CT</td>
<td>1442382</td>
<td>117063</td>
<td>POLYGON ((-8186995.178656538 5019223.193891366...</td>
<td>...</td>
<td>0.013289</td>
<td>0.051753</td>
<td>0.064533</td>
<td>0.000000</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>2</td>
<td>1548918.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>9</td>
<td>1</td>
<td>43100</td>
<td>1400000US09001043100</td>
<td>9001043100</td>
<td>431.0</td>
<td>CT</td>
<td>6652660</td>
<td>58522</td>
<td>POLYGON ((-8178763.436270848 5029936.759394648...</td>
<td>...</td>
<td>0.000000</td>
<td>0.001484</td>
<td>0.010249</td>
<td>0.000073</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>11</td>
<td>6698858.0</td>
</tr>
</tbody>
</table>

<p>5 rows × 88 columns</p>
</div>
</div>
</div>
<div id="cell-33" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Separate predictors and outcome</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> data.iloc[:,<span class="dv">68</span>:<span class="op">-</span><span class="dv">2</span>]</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data[<span class="st">"PopDensity"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We had an issue where our results were not quite matching those of <code>scikit-learn</code> and we discovered that this was due to a way we set up our dataset. Since we have calculated the proportion of pixels in each tract belonging to each landcover class, the landcovers sum to 1 in every row. Since we create an additional column of ones in order to calculate a y-intercept for linear regression with gradient descent, this means that our y-intercept column is equal to the sum of our other columns. In other words, the constant column is linearly dependent on our other predictor columns. To address this issue, we drop some columns that seem unimportant. Specifically, these columns are mostly zero, meaning that they are not very common in Connecticut anyway.</p>
<div id="cell-35" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Drop some landcovers to address issue of linear combination </span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> X[[<span class="st">'2'</span>, <span class="st">'5'</span>, <span class="st">'11'</span>, <span class="st">'12'</span>, <span class="st">'8'</span>, <span class="st">'13'</span>, <span class="st">'14'</span>, <span class="st">'15'</span>, <span class="st">'20'</span>, <span class="st">'21'</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="linear-regression-with-no-penalty-term" class="level2">
<h2 class="anchored" data-anchor-id="linear-regression-with-no-penalty-term">Linear Regression with No Penalty Term</h2>
<section id="sci-kit-learn" class="level3">
<h3 class="anchored" data-anchor-id="sci-kit-learn">Sci-kit Learn</h3>
<section id="train-model" class="level4">
<h4 class="anchored" data-anchor-id="train-model">Train Model</h4>
<p>First, we fit a linear regression model with scikit-learn. We do this simply to verify against our own implementation of linear regression.</p>
<div id="cell-37" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit model</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Doing this just for the purpose of seeing what it looks like</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="co"># We can use the results from this package to verify that our implementation is working properly</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="co">#Train and test split creation</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>LR_s <span class="op">=</span> LinearRegression() </span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> LR_s.fit(X_train, y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Linear regression seeks to minimize the mean squared error, so we report the mean square error from <code>scikit-learn</code>’s model here.</p>
<div id="cell-39" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># MSE</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>mean_squared_error(y_train, LR_s.predict(X_train))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>227396.12768129486</code></pre>
</div>
</div>
<p>Let’s check the <span class="math inline">\(R^2\)</span> value of our model. Recall that <span class="math inline">\(R^2\)</span> is also known as the <em>coefficient of determination</em>, and it represents the proportion of variation in one’s outcome variable that is explained by one’s model.</p>
<div id="cell-41" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># R^2 value</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>m.score(X_train, y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>0.7723901708932351</code></pre>
</div>
</div>
<p>With an <span class="math inline">\(R^2\)</span> value of roughly <span class="math inline">\(0.772\)</span>, our ordinary least squares regression model accounts for about <span class="math inline">\(77.2\)</span>% of the variation of the population densities in Connecticut’s tracts.</p>
<p>Let’s inspect the y-intercept and coefficients to verify that our coefficients seem logical.</p>
<div id="cell-43" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Y-intercept</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Intercept:"</span>, m.intercept_)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Min and max population density</span></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Population Density Min:"</span>, y_train.<span class="bu">min</span>())</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Population Density Max:"</span>, y_train.<span class="bu">max</span>())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Intercept: 983.2395073145441
Population Density Min: 0.0
Population Density Max: 6084.305602883675</code></pre>
</div>
</div>
<p>Since our predictions are proportions of pixels in a tract of a given landcover, it is impossible for all of our predictors to be zero. Basically this means that no tract will be in the situation where all variables are equal to zero, leaving the y-intercept as its population density. However, in theory, in the absence of any landcover pixels, the population density would be <span class="math inline">\(983\)</span> people per square kilometer. With <code>y_train</code> ranging from 0 to 6084, this seems somewhat reasonable.</p>
<div id="cell-45" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Variable coefficients</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>m.coef_</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>array([  3409.40801231,  -2942.65854175,   -917.38563842,  -4525.6598175 ,
          668.32452458,  -2125.96537456,  -1746.52921947,  -1576.35637606,
       -13652.09857612,  -1417.12360532])</code></pre>
</div>
</div>
<div id="cell-46" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Columns</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>X.columns</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>Index(['2', '5', '11', '12', '8', '13', '14', '15', '20', '21'], dtype='object')</code></pre>
</div>
</div>
<p>Most of these coefficients are negative, indicating that as the proportion of pixels representing a given landcover type increases, the population density of the tract decreases. The only positive values are the coefficient of <code>2</code>, which represents developed impervious landcover, and the coefficient of <code>8</code>, which represents grassland/herbaceous landcover. We definitely anticipated a positive coefficient for <code>2</code>, as impervious developed surfaces like buildings and roads are a major marker of human presence. The documentation indicates that while this landcover cannot be used for tilling, it can be used for grazing, so perhaps the positive coefficient is indicative of population density associated with farming. Also, Connecticut is generally forested in rural areas, so grassy areas are likely in suburbia or near urban areas. The magnitude of <code>2</code> is much larger than <code>8</code>, however, indicating that developed impervious landcover is the most important factor increasing population density.</p>
<p>The negative coefficients correspond to developed open space, mixed forest, shrub, palustrine forested wetland, palustrine scrub/shrub wetland, palustrine emergent wetland, barren land, and open water. With the exception of developed open space, these landcovers are generally not associated with population density. And developed open space does not necessitate people living in that location – people could live in one tract and commute to a tract with developed open space for recreational purposes, for example. Thus it makes sense that increased values of these variables contribute to less population density.</p>
</section>
<section id="test-model" class="level4">
<h4 class="anchored" data-anchor-id="test-model">Test Model</h4>
<p>Now that we have evaluated the basic interpretation of our model on our training data, let us check the performance of our model on our testing data. First, we calculate our predictions.</p>
<div id="cell-48" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create predictions (on test data)</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> LR_s.predict(X_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let us inspect the mean square error of our model on the testing data.</p>
<div id="cell-50" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># MSE</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>mean_squared_error(y_test, preds)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>373799.85511504946</code></pre>
</div>
</div>
<p>At <span class="math inline">\(373,800\)</span>, the mean squared error of our model on the testing data is much larger than the mean squared error on the training data, which was <span class="math inline">\(227,396\)</span>. This makes sense as our model was fit specifically to the tendencies of the training data.</p>
<p>To evaluate the explanatory power of our model, let’s also calculate the <span class="math inline">\(R^2\)</span> value on our testing data.</p>
<div id="cell-52" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Test R^2 value</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>r2_score(y_test, preds)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>0.7086666350845903</code></pre>
</div>
</div>
<p>As one might anticipate, the <span class="math inline">\(R^2\)</span> value of the testing data is lower than the training data. However, at <span class="math inline">\(0.709\)</span>, the <span class="math inline">\(R^2\)</span> of the testing data is only <span class="math inline">\(0.064\)</span> lower than the <span class="math inline">\(R^2\)</span> of the training data. In other words, our model explains <span class="math inline">\(6.4\)</span>% less of the variation of the population density in our testing data. This is not a negligible amount, but we are still relatively satisfied with a model that explains over <span class="math inline">\(70\)</span>% of the variation in population density.</p>
</section>
</section>
<section id="our-implementation" class="level3">
<h3 class="anchored" data-anchor-id="our-implementation">Our Implementation</h3>
<p>We implemented ordinary linear regression with gradient descent in <a href="linear_regression.py"><code>linear_regression.py</code></a>. Let us train the model using our implementation and verify that our results roughly match those of <code>scikit-learn</code>.</p>
<section id="train-model-1" class="level4">
<h4 class="anchored" data-anchor-id="train-model-1">Train Model</h4>
<p>First, we need to convert our training and testing data to the <code>torch.tensor</code> format to match the expected input of our model. We also add a column of ones at the end of the X training and testing data for the purposes of training our y-intercept.</p>
<div id="cell-55" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># convert to torch tensors</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="co"># add column of ones for y-intercept</span></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>X_train_torch <span class="op">=</span> torch.cat((torch.tensor(X_train.values), torch.ones((X_train.shape[<span class="dv">0</span>], <span class="dv">1</span>))), <span class="dv">1</span>)</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>y_train_torch <span class="op">=</span> torch.tensor(y_train.values)</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>X_test_torch <span class="op">=</span> torch.cat((torch.tensor(X_test.values), torch.ones((X_test.shape[<span class="dv">0</span>], <span class="dv">1</span>))), <span class="dv">1</span>)</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>y_test_torch <span class="op">=</span> torch.tensor(y_test.values)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now that we have our data in the appropriate format, we can train our model.</p>
<div id="cell-57" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># fit linear regression model</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>LR <span class="op">=</span> LinearRegress()</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>opt <span class="op">=</span> GradientDescentOptimizer(LR)</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a><span class="co"># initialize vector to record loss values</span></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>loss_vec <span class="op">=</span> []</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a><span class="co"># fit model</span></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">500000</span>): </span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># update model</span></span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a>    opt.step(X_train_torch, y_train_torch, alpha <span class="op">=</span> <span class="fl">0.01</span>)</span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># calculate and record loss</span></span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> LR.loss(X_train_torch, y_train_torch) </span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a>    loss_vec.append(loss)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s inspect the evolution of our loss function (mean squared error) to verify that our model has converged to a solution.</p>
<div id="cell-59" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the changes in loss </span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>plt.plot(loss_vec, color <span class="op">=</span> <span class="st">"slategrey"</span>)</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>labs <span class="op">=</span> plt.gca().<span class="bu">set</span>(xlabel <span class="op">=</span> <span class="st">"Iteration"</span>, ylabel <span class="op">=</span> <span class="st">"Loss"</span>)</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Loss Function Throughout Model Training"</span>)<span class="op">;</span></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a><span class="co"># MSE</span></span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Mean squared error after training:"</span>, LR.mse(X_train_torch, y_train_torch).item())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Mean squared error after training: 227396.1319467965</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="final_project_files/figure-html/cell-28-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Great! After <span class="math inline">\(500,000\)</span> iterations, our mean squared error is <span class="math inline">\(227,396.132\)</span>, which is essentially equivalent to the mean squared error of <span class="math inline">\(227,396.128\)</span> found by <code>scikit-learn</code>.</p>
<p>Let’s inspect the y-intercept and coefficients to verify that they are similar to <code>scikit-learn</code>’s solution.</p>
<div id="cell-61" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Y-intercept</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>LR.w[<span class="op">-</span><span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<pre><code>tensor(983.0291, dtype=torch.float64)</code></pre>
</div>
</div>
<p>This y-intercept is also similar to the figure of <span class="math inline">\(983.2395\)</span> reported by <code>scikit-learn</code>.</p>
<div id="cell-63" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Variable coefficients</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Coefficients:"</span>, LR.w[:<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Differences in signs</span></span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Differences in sign:"</span>, (torch.tensor(m.coef_)<span class="op">*</span>LR.w[:<span class="op">-</span><span class="dv">1</span>]<span class="op">&lt;</span> <span class="dv">0</span>).<span class="bu">sum</span>().item())</span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Maximum difference in coefficient</span></span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Maximum coefficient difference:"</span>, torch.<span class="bu">abs</span>((torch.tensor(m.coef_)<span class="op">-</span>LR.w[:<span class="op">-</span><span class="dv">1</span>])).<span class="bu">max</span>().item())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Coefficients: tensor([  3409.6334,  -2942.3605,   -917.2350,  -4527.3370,    669.5791,
         -2126.6514,  -1721.1996,  -1578.8776, -13651.8922,  -1416.8399],
       dtype=torch.float64)
Differences in sign: 0
Maximum coefficient difference: 25.329603726808955</code></pre>
</div>
</div>
<p>Our coefficients are very similar to those from <code>scikit-learn</code>’s solution! All coefficients have the same sign and the maximum difference between a coefficient in our two models is <span class="math inline">\(25\)</span>. Considering the magnitude of the coefficients, this difference is relatively small. Thus the interpretation of our model matches the interpretation of <code>scikit-learn</code>’s model, making us confident that we have implemented linear regression correctly.</p>
<div id="cell-65" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute R^2 score</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>LR.r2(X_train_torch, y_train_torch)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="30">
<pre><code>tensor(0.7724, dtype=torch.float64)</code></pre>
</div>
</div>
<p>Our <span class="math inline">\(R^2\)</span> value is the same as <code>scikit-learn</code>’s.</p>
</section>
<section id="test-model-1" class="level4">
<h4 class="anchored" data-anchor-id="test-model-1">Test Model</h4>
<p>Now we inspect our model’s performance on the testing data.</p>
<div id="cell-68" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># MSE</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>LR.mse(X_test_torch, y_test_torch)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<pre><code>tensor(373801.8165, dtype=torch.float64)</code></pre>
</div>
</div>
<p>At <span class="math inline">\(373,802\)</span>, our implementation’s testing MSE is very similar to <code>scikit-learn</code>’s <span class="math inline">\(373,800\)</span>, indicating similar performance. Once again, this is substantially larger than the training MSE, indicating that our model did not generalize perfectly.</p>
<div id="cell-70" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="co"># R^2 value</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>LR.r2(X_test_torch, y_test_torch)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="32">
<pre><code>tensor(0.7087, dtype=torch.float64)</code></pre>
</div>
</div>
<p><code>Scikit-learn</code>’s testing <span class="math inline">\(R^2\)</span> value was also <span class="math inline">\(0.7087\)</span>! Overall, it appears that we have succesfully implemented linear regression in a manner that achieves similar results to <code>scikit-learn</code>.</p>
</section>
</section>
</section>
<section id="linear-regression-with-ell_1-regularization" class="level2">
<h2 class="anchored" data-anchor-id="linear-regression-with-ell_1-regularization">Linear Regression with <span class="math inline">\(\ell_1\)</span> Regularization</h2>
<section id="sci-kit-learn-1" class="level3">
<h3 class="anchored" data-anchor-id="sci-kit-learn-1">Sci-kit Learn</h3>
<section id="train-model-2" class="level4">
<h4 class="anchored" data-anchor-id="train-model-2">Train Model</h4>
<p>First, we fit the model with <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html"><code>scikit-learn Lasso</code></a> and inspect the resulting model. As before, we do this simply to verify against our own implementation.</p>
<div id="cell-73" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit model</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>LR_s_l1 <span class="op">=</span> Lasso(alpha <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> LR_s_l1.fit(X_train, y_train)</span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Report results</span></span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"MSE:"</span>, mean_squared_error(y_train, LR_s_l1.predict(X_train)),</span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a>      <span class="st">"</span><span class="ch">\n</span><span class="st">R^2:"</span>, m.score(X_train, y_train),</span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a>      <span class="st">"</span><span class="ch">\n</span><span class="st">Y-intercept:"</span>, m.intercept_,</span>
<span id="cb55-10"><a href="#cb55-10" aria-hidden="true" tabindex="-1"></a>      <span class="st">"</span><span class="ch">\n</span><span class="st">Coefficients:</span><span class="ch">\n</span><span class="st">"</span>, m.coef_)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>MSE: 236944.40360579122 
R^2: 0.7628329217280919 
Y-intercept: -191.72480712350455 
Coefficients:
 [ 4358.88007237 -1696.29039686   224.06934601    -0.
     0.            -0.            -0.            -0.
 -6028.66936275  -279.44578393]</code></pre>
</div>
</div>
<div id="cell-74" class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Columns</span></span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>X.columns</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="34">
<pre><code>Index(['2', '5', '11', '12', '8', '13', '14', '15', '20', '21'], dtype='object')</code></pre>
</div>
</div>
<p>The training MSE is slightly larger and the training <span class="math inline">\(R^2\)</span> is slightly smaller than linear regression with no regularizer, which makes sense as we have applied a penalty to help prevent overfitting. The y-intercept is closer to <span class="math inline">\(0\)</span>, and many of the coefficients are equal to exactly <span class="math inline">\(0\)</span>, making them more interpretable: some coefficients simply do not matter! In this model, landcover <code>2</code> (developed impervious) again has a positive coefficient, and with a large magnitude, it remains the main driver in high population density. There is one other variable, <code>11</code> (mixed forest), which has a positive coefficient. Interestingly, it was negative in the other model, leading to confusion in its interpretation. But with a somewhat small magnitude, this variable overall has a minor impact on population density, only changing the population density by 224 people per square kilometer as its value increases from 0 to 1. With the <span class="math inline">\(\ell_1\)</span> regularizer, the landcovers of shrub, grassland/herbaceous, palustrine forested wetland, palustrine scrub/shrub wetland, and palustrine emergent wetland are now equal to zero. These coefficients must not have been that important to the model, as our regularizer made them have zero impact on population density. Variables with negative coefficients are developed open space, barren land, and open water, probably for the same reasons that they were negative earlier.</p>
</section>
<section id="test-model-2" class="level4">
<h4 class="anchored" data-anchor-id="test-model-2">Test Model</h4>
<p>Next, we discover whether the <span class="math inline">\(\ell_1\)</span> regularizer actually made the model generalize better to the testing data.</p>
<div id="cell-77" class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create predictions (on test data)</span></span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> LR_s_l1.predict(X_test)</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Report results</span></span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"MSE:"</span>, mean_squared_error(y_test, preds),</span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a>      <span class="st">"</span><span class="ch">\n</span><span class="st">R^2:"</span>, r2_score(y_test, preds))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>MSE: 390639.95954704983 
R^2: 0.6955417389066836</code></pre>
</div>
</div>
<p>Our new MSE of <span class="math inline">\(390,639\)</span> is actually larger than the MSE of <span class="math inline">\(373,800\)</span> with no regularizer, indicating that the <span class="math inline">\(\ell_1\)</span> regularizer did not help our model generalize to the testing data. Furthermore, the <span class="math inline">\(R^2\)</span> value was larger in the previous model, meaning that the model with no regularizer explained more variation in the outcome variable.</p>
</section>
</section>
<section id="our-implementation-1" class="level3">
<h3 class="anchored" data-anchor-id="our-implementation-1">Our Implementation</h3>
<p>Let’s fit linear regression with the <span class="math inline">\(\ell_1\)</span> norm with our own implementation and verify that our results match those of <code>scikit-learn</code>. Note that <code>scikit-learn</code> uses an algorithm known as <em>coordinate descent</em> to find their solution, but we learned about <em>gradient descent</em> in this class. <em>Coordinate descent</em> is better suited for lasso regression because it allows some coefficients to equal exactly zero. Gradient descent with the <span class="math inline">\(\ell_1\)</span> norm makes some coefficients much smaller, but does not cause any of them to equal exactly zero. To mimick their results, in our implementation we set our coefficients equal to zero if they are below a selected threshold. We allow our model <span class="math inline">\(5000\)</span> iterations to begin learning the coefficients before applying this threshold.</p>
<section id="train-model-3" class="level4">
<h4 class="anchored" data-anchor-id="train-model-3">Train Model</h4>
<div id="cell-80" class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="co"># fit linear regression model</span></span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>LR_l1 <span class="op">=</span> LinearRegress(penalty <span class="op">=</span> <span class="st">"l1"</span>, lam <span class="op">=</span> <span class="dv">1</span>) <span class="co"># 1 in scikit-learn</span></span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>opt_l1 <span class="op">=</span> GradientDescentOptimizer(LR_l1)</span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a><span class="co"># initialize vector to record loss values</span></span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a>loss_vec_l1 <span class="op">=</span> []</span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a><span class="co"># fit model</span></span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50000</span>):</span>
<span id="cb61-10"><a href="#cb61-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># update model</span></span>
<span id="cb61-11"><a href="#cb61-11" aria-hidden="true" tabindex="-1"></a>    opt_l1.step(X_train_torch, y_train_torch, alpha <span class="op">=</span> <span class="fl">0.001</span>)</span>
<span id="cb61-12"><a href="#cb61-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-13"><a href="#cb61-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># set coefs equal to zero after model has had enough learning time</span></span>
<span id="cb61-14"><a href="#cb61-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> i <span class="op">&gt;</span> <span class="dv">5000</span>:</span>
<span id="cb61-15"><a href="#cb61-15" aria-hidden="true" tabindex="-1"></a>        LR_l1.w[torch.<span class="bu">abs</span>(LR_l1.w) <span class="op">&lt;</span> <span class="dv">500</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb61-16"><a href="#cb61-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-17"><a href="#cb61-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># calculate and record loss</span></span>
<span id="cb61-18"><a href="#cb61-18" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> LR_l1.loss(X_train_torch, y_train_torch) </span>
<span id="cb61-19"><a href="#cb61-19" aria-hidden="true" tabindex="-1"></a>    loss_vec_l1.append(loss)</span>
<span id="cb61-20"><a href="#cb61-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-21"><a href="#cb61-21" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the changes in loss </span></span>
<span id="cb61-22"><a href="#cb61-22" aria-hidden="true" tabindex="-1"></a>plt.plot(loss_vec_l1, color <span class="op">=</span> <span class="st">"slategrey"</span>)</span>
<span id="cb61-23"><a href="#cb61-23" aria-hidden="true" tabindex="-1"></a>labs <span class="op">=</span> plt.gca().<span class="bu">set</span>(xlabel <span class="op">=</span> <span class="st">"Iteration"</span>, ylabel <span class="op">=</span> <span class="st">"Loss"</span>)</span>
<span id="cb61-24"><a href="#cb61-24" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Loss Function Throughout Model Training"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="final_project_files/figure-html/cell-37-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>It appears that our model converged to a solution with a similar loss function value! Note that the small upwards blip in the loss function occured at iteration <span class="math inline">\(5000\)</span> when we began allowing our model to set some coefficients equal to zero. Let us inspect our results and compare them to <code>scikit-learn</code>’s output.</p>
<div id="cell-82" class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Report results</span></span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"MSE:"</span>, LR_l1.mse(X_train_torch, y_train_torch).item(),</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a>      <span class="st">"</span><span class="ch">\n</span><span class="st">R^2:"</span>, LR_l1.r2(X_train_torch, y_train_torch),</span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a>      <span class="st">"</span><span class="ch">\n</span><span class="st">Y-intercept:"</span>, LR_l1.w[<span class="op">-</span><span class="dv">1</span>],</span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a>      <span class="st">"</span><span class="ch">\n</span><span class="st">Coefficients:</span><span class="ch">\n</span><span class="st">"</span>, LR_l1.w[:<span class="op">-</span><span class="dv">1</span>],</span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a>      <span class="st">"</span><span class="ch">\n</span><span class="st">Differences in sign:"</span>, (torch.tensor(m.coef_)<span class="op">*</span>LR_l1.w[:<span class="op">-</span><span class="dv">1</span>]<span class="op">&lt;</span> <span class="dv">0</span>).<span class="bu">sum</span>().item(),</span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a>      <span class="st">"</span><span class="ch">\n</span><span class="st">Maximum coefficient difference:"</span>, torch.<span class="bu">abs</span>((torch.tensor(m.coef_)<span class="op">-</span>LR_l1.w[:<span class="op">-</span><span class="dv">1</span>])).<span class="bu">max</span>().item())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>MSE: 233736.21710488532 
R^2: tensor(0.7660, dtype=torch.float64) 
Y-intercept: tensor(0., dtype=torch.float64) 
Coefficients:
 tensor([ 4257.6646, -1977.7857,     0.0000,     0.0000,     0.0000,     0.0000,
            0.0000,     0.0000, -7781.5773,  -551.3119], dtype=torch.float64) 
Differences in sign: 0 
Maximum coefficient difference: 1752.9079262978257</code></pre>
</div>
</div>
<p>Our model’s MSE of <span class="math inline">\(233,736\)</span> is slightly smaller than <code>scikit-learn</code>’s MSE of <span class="math inline">\(236,944\)</span> and our model’s <span class="math inline">\(R^2\)</span> of <span class="math inline">\(0.7660\)</span> is slightly larger than <code>scikit-learn</code>’s <span class="math inline">\(R^2\)</span> of <span class="math inline">\(0.7628\)</span>, indicating that our linear regression model with the <span class="math inline">\(\ell_1\)</span> norm performed marginally better than theirs. This difference could have occured due to differences in the optimizer and the number of training iterations. Additionally, these MSE and <span class="math inline">\(R^2\)</span> metrics are both slightly worse than what our implementation achieved with no regularizer, which makes sense as we are attempting to prevent overfitting.</p>
<p>One should note that our workaround for setting coefficients equal to zero is not ideal for several reasons. First, we hard-coded a certain threshold for choosing coefficients to set equal to zero, as well as a certain number of iterations at which to begin checking for these low-magnitude coefficients. Most users probably do not want to decide on such a threshold. Second, our method did not exactly replicate the output from <code>scikit-learn</code>. Adjusting our parameters to exactly reproduce the coefficients set to zero proved difficult, and the best we were able to do involved setting the y-intercept and landcover <code>11</code> equal to zero, while they were nonzero in <code>scikit-learn</code>’s solution. Landcover <code>11</code> represents mixed forest and was the one coefficient with a somewhat counterintuitive value in <code>scikit-learn</code>’s model, so in terms of interpretation, our new model still makes sense. All coefficients have the same sign as <code>scikit-learn</code>’s model with similar magnitudes, making us confident that our model is successfully describing the situation, despite the minor discrepancies.</p>
</section>
<section id="test-model-3" class="level4">
<h4 class="anchored" data-anchor-id="test-model-3">Test Model</h4>
<div id="cell-84" class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Report results</span></span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"MSE:"</span>, LR_l1.mse(X_test_torch, y_test_torch),</span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a>      <span class="st">"</span><span class="ch">\n</span><span class="st">R^2:"</span>, LR_l1.r2(X_test_torch, y_test_torch))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>MSE: tensor(384765.6761, dtype=torch.float64) 
R^2: tensor(0.7001, dtype=torch.float64)</code></pre>
</div>
</div>
<p>These values are pretty similar to the ones we have seen already. At <span class="math inline">\(384,766\)</span>, our implementation’s MSE is less than <code>scikit-learn</code>’s <span class="math inline">\(390,640\)</span>, and at <span class="math inline">\(0.7001\)</span>, our implementation’s <span class="math inline">\(R^2\)</span> is slightly more than <code>scikit-learn</code>’s <span class="math inline">\(0.6955\)</span>. This means that our model generalized slightly better to the testing data, in addition to performing better on the training data. Again, this can likely be explained by differences in the optimization method and the number of training iterations.</p>
<p>Furthermore, this MSE is slightly larger than the <span class="math inline">\(373,802\)</span> figure returned by our implementation of linear regression with no penalty term, and this <span class="math inline">\(R^2\)</span> is slighly smaller than the <span class="math inline">\(0.7087\)</span> figure, indicating that linear regression with the <span class="math inline">\(\ell_1\)</span> penalty did not generalize better to the testing data.</p>
</section>
</section>
</section>
<section id="linear-regression-with-ell_2-regularization" class="level2">
<h2 class="anchored" data-anchor-id="linear-regression-with-ell_2-regularization">Linear Regression with <span class="math inline">\(\ell_2\)</span> Regularization</h2>
<section id="sci-kit-learn-2" class="level3">
<h3 class="anchored" data-anchor-id="sci-kit-learn-2">Sci-kit Learn</h3>
<section id="train-model-4" class="level4">
<h4 class="anchored" data-anchor-id="train-model-4">Train Model</h4>
<p>First, we fit the model with <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html"><code>scikit-learn Ridge</code></a> and inspect the resulting model. As before, we do this to assess the validity of our own implementation.</p>
<div id="cell-87" class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit model</span></span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>LR_s_l2 <span class="op">=</span> Ridge(alpha <span class="op">=</span> <span class="fl">.1</span>)</span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> LR_s_l2.fit(X_train, y_train)</span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Report results</span></span>
<span id="cb66-7"><a href="#cb66-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"MSE:"</span>, mean_squared_error(y_train, LR_s_l2.predict(X_train)),</span>
<span id="cb66-8"><a href="#cb66-8" aria-hidden="true" tabindex="-1"></a>      <span class="st">"</span><span class="ch">\n</span><span class="st">R^2:"</span>, m.score(X_train, y_train),</span>
<span id="cb66-9"><a href="#cb66-9" aria-hidden="true" tabindex="-1"></a>      <span class="st">"</span><span class="ch">\n</span><span class="st">Y-intercept:"</span>, m.intercept_,</span>
<span id="cb66-10"><a href="#cb66-10" aria-hidden="true" tabindex="-1"></a>      <span class="st">"</span><span class="ch">\n</span><span class="st">Coefficients:</span><span class="ch">\n</span><span class="st">"</span>, m.coef_)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>MSE: 235049.69085940512 
R^2: 0.7647294150800621 
Y-intercept: 69.8570955883946 
Coefficients:
 [ 4146.87047622 -2058.81157194     6.57006522 -1039.66258053
   107.03266863  -815.93549227  -127.78253829  -231.19197573
 -6438.07336424  -692.08973348]</code></pre>
</div>
</div>
<div id="cell-88" class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Columns</span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>X.columns</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="40">
<pre><code>Index(['2', '5', '11', '12', '8', '13', '14', '15', '20', '21'], dtype='object')</code></pre>
</div>
</div>
<p>The training MSE is larger and the training <span class="math inline">\(R^2\)</span> is smaller than <code>scikit-learn</code>’s linear regression with no regularizer. We anticipated this would be true in comparison to the no regularizer model as the penalty term helps prevent overfitting. It appears that with our chosen parameters, lasso regression performed better than ridge regression in terms of both MSE and <span class="math inline">\(R^2\)</span>, but this will change depending on the selected value for parameters.</p>
<p>The y-intercept and all coefficients except for landcover <code>2</code> are smaller than they were under linear regression without regularization, indicating that the regularization method has been successful in decreasing the magnitude of our coefficients. None of the coefficients are equal to exactly zero, but that is to be expected when working with the <span class="math inline">\(\ell_2\)</span> penalty.</p>
<p>The sign of every coefficient in this model is the same as in the original linear regression model except for landcover <code>11</code> (mixed forest), which is now positive and was also positive under lasso regression. However, the magnitude of this coefficient is really small; at 6.57, a location’s population density only changes by 6.57 people per square kilometer as the proportion of pixels represented by mixed forest increases from 0 to 1.</p>
</section>
<section id="test-model-4" class="level4">
<h4 class="anchored" data-anchor-id="test-model-4">Test Model</h4>
<div id="cell-90" class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create predictions (on test data)</span></span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> LR_s_l2.predict(X_test)</span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Report results</span></span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"MSE:"</span>, mean_squared_error(y_test, preds),</span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a>      <span class="st">"</span><span class="ch">\n</span><span class="st">R^2:"</span>, r2_score(y_test, preds))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>MSE: 387635.2059385676 
R^2: 0.6978835936921313</code></pre>
</div>
</div>
<p>On the testing data, our MSE of <span class="math inline">\(387,635\)</span> is similar to the result of <span class="math inline">\(390,640\)</span> with the <span class="math inline">\(\ell_1\)</span> regularizer but larger than the MSE of <span class="math inline">\(373,800\)</span> with no regularizer, indicating that the <span class="math inline">\(\ell_2\)</span> regularizer also did not help our model generalize to the testing data better than unregularized linear regression. The <span class="math inline">\(R^2\)</span> value was also larger in linear regression, meaning that the model without regularization explained more variation in the outcome variable.</p>
</section>
</section>
<section id="our-implementation-2" class="level3">
<h3 class="anchored" data-anchor-id="our-implementation-2">Our Implementation</h3>
<section id="train-model-5" class="level4">
<h4 class="anchored" data-anchor-id="train-model-5">Train Model</h4>
<p>Let’s fit linear regression with the <span class="math inline">\(\ell_1\)</span> norm with our own implementation and verify that our results are reasonably similar to those of <code>scikit-learn</code>.</p>
<div id="cell-93" class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="co"># fit linear regression model</span></span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>LR_l2 <span class="op">=</span> LinearRegress(penalty <span class="op">=</span> <span class="st">"l2"</span>, lam <span class="op">=</span> <span class="fl">.1</span><span class="op">/</span>X_train_torch.shape[<span class="dv">0</span>]) </span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a>opt_l2 <span class="op">=</span> GradientDescentOptimizer(LR_l2)</span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a><span class="co"># initialize vector to record loss values</span></span>
<span id="cb72-6"><a href="#cb72-6" aria-hidden="true" tabindex="-1"></a>loss_vec_l2 <span class="op">=</span> []</span>
<span id="cb72-7"><a href="#cb72-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-8"><a href="#cb72-8" aria-hidden="true" tabindex="-1"></a><span class="co"># fit model</span></span>
<span id="cb72-9"><a href="#cb72-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1000000</span>): </span>
<span id="cb72-10"><a href="#cb72-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># update model</span></span>
<span id="cb72-11"><a href="#cb72-11" aria-hidden="true" tabindex="-1"></a>    opt_l2.step(X_train_torch, y_train_torch, alpha <span class="op">=</span> <span class="fl">0.00001</span>)</span>
<span id="cb72-12"><a href="#cb72-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-13"><a href="#cb72-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># calculate and record loss</span></span>
<span id="cb72-14"><a href="#cb72-14" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> LR_l2.loss(X_train_torch, y_train_torch) </span>
<span id="cb72-15"><a href="#cb72-15" aria-hidden="true" tabindex="-1"></a>    loss_vec_l2.append(loss)</span>
<span id="cb72-16"><a href="#cb72-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-17"><a href="#cb72-17" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the changes in loss </span></span>
<span id="cb72-18"><a href="#cb72-18" aria-hidden="true" tabindex="-1"></a>plt.plot(loss_vec_l2, color <span class="op">=</span> <span class="st">"slategrey"</span>)</span>
<span id="cb72-19"><a href="#cb72-19" aria-hidden="true" tabindex="-1"></a>labs <span class="op">=</span> plt.gca().<span class="bu">set</span>(xlabel <span class="op">=</span> <span class="st">"Iteration"</span>, ylabel <span class="op">=</span> <span class="st">"Loss"</span>)</span>
<span id="cb72-20"><a href="#cb72-20" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Loss Function Throughout Model Training"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="final_project_files/figure-html/cell-43-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-94" class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>m.coef_</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="43">
<pre><code>array([ 4146.87047622, -2058.81157194,     6.57006522, -1039.66258053,
         107.03266863,  -815.93549227,  -127.78253829,  -231.19197573,
       -6438.07336424,  -692.08973348])</code></pre>
</div>
</div>
<div id="cell-95" class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Report results</span></span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"MSE:"</span>, LR_l2.mse(X_train_torch, y_train_torch).item(),</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a>      <span class="st">"</span><span class="ch">\n</span><span class="st">R^2:"</span>, LR_l2.r2(X_train_torch, y_train_torch),</span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a>      <span class="st">"</span><span class="ch">\n</span><span class="st">Y-intercept:"</span>, LR_l2.w[<span class="op">-</span><span class="dv">1</span>],</span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a>      <span class="st">"</span><span class="ch">\n</span><span class="st">Coefficients:</span><span class="ch">\n</span><span class="st">"</span>, LR_l2.w[:<span class="op">-</span><span class="dv">1</span>],</span>
<span id="cb75-6"><a href="#cb75-6" aria-hidden="true" tabindex="-1"></a>      <span class="st">"</span><span class="ch">\n</span><span class="st">Differences in sign:"</span>, (torch.tensor(m.coef_)<span class="op">*</span>LR_l2.w[:<span class="op">-</span><span class="dv">1</span>]<span class="op">&lt;</span> <span class="dv">0</span>).<span class="bu">sum</span>().item(),</span>
<span id="cb75-7"><a href="#cb75-7" aria-hidden="true" tabindex="-1"></a>      <span class="st">"</span><span class="ch">\n</span><span class="st">Maximum coefficient difference:"</span>, torch.<span class="bu">abs</span>((torch.tensor(m.coef_)<span class="op">-</span>LR_l2.w[:<span class="op">-</span><span class="dv">1</span>])).<span class="bu">max</span>().item())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>MSE: 246031.0025521462 
R^2: tensor(0.7537, dtype=torch.float64) 
Y-intercept: tensor(-258.6768, dtype=torch.float64) 
Coefficients:
 tensor([ 4417.6162, -1821.4942,   373.5831,  -372.9745,  -251.1601,  -436.8005,
          -43.2542,  -109.9865, -2181.9550,  -541.2076], dtype=torch.float64) 
Differences in sign: 1 
Maximum coefficient difference: 4256.118320893194</code></pre>
</div>
</div>
<div id="cell-96" class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>X.columns</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="45">
<pre><code>Index(['2', '5', '11', '12', '8', '13', '14', '15', '20', '21'], dtype='object')</code></pre>
</div>
</div>
<p>First of all, our implementation does not generate identical output to <code>scikit-learn</code>’s implementation. In order to make our implementation converge to a solution, we needed to make <span class="math inline">\(\lambda\)</span> far smaller than in their implementation. This may have occurred because we are using the optimization technique of gradient descent, but <code>scikit-learn</code> has implemented a number of more complex techniques and automatically detects which one to use depending on the dataset it receives as input. It is also possible that they implemented their loss function as the sum of squared error rather than the mean squared error. If this is the case, then dividing our <span class="math inline">\(\lambda\)</span> by the number of observations should theoretically produce identical results. In the code above, we opt for this implementation; however, it should be noted that we have not confirmed whether <code>scikit-learn</code> actually uses the sum of squares in their loss function. Even with this modification, our model has converged to a different solution than theirs, for reasons we have not uncovered.</p>
<p>Although our results are different, they are not drastically different. Our MSE is <span class="math inline">\(246,030\)</span> rather than <span class="math inline">\(235,050\)</span> and our <span class="math inline">\(R^2\)</span> is <span class="math inline">\(0.7537\)</span> rather than <span class="math inline">\(0.7647\)</span>, differences that are not ideal but also not terrible. All coefficients have the same sign as their solution except for <code>8</code> (grassland/herbaceous). In all prior models, the coefficient of landcover <code>8</code> has been positive or zero, but in this model, it is negative! This confuses the interpretation of landcover <code>8</code>, but with only one discrepancy it does not necessarily ring alarm bells. Perhaps if we had the time to confirm <code>scikit-learn</code>’s loss function and implement the same optimization method we would achive more similar results.</p>
</section>
<section id="test-model-5" class="level4">
<h4 class="anchored" data-anchor-id="test-model-5">Test Model</h4>
<div id="cell-99" class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Report results</span></span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"MSE:"</span>, LR_l2.mse(X_test_torch, y_test_torch),</span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a>      <span class="st">"</span><span class="ch">\n</span><span class="st">R^2:"</span>, LR_l2.r2(X_test_torch, y_test_torch))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>MSE: tensor(399693.2117, dtype=torch.float64) 
R^2: tensor(0.6885, dtype=torch.float64)</code></pre>
</div>
</div>
<p>At <span class="math inline">\(399,692\)</span>, our implementation’s MSE is more than <code>scikit-learn</code>’s <span class="math inline">\(387,635\)</span> as well as all prior results. And at <span class="math inline">\(0.6885\)</span>, our implementation’s <span class="math inline">\(R^2\)</span> is less than <code>scikit-learn</code>’s <span class="math inline">\(0.6979\)</span> and all other results. We could achieve better results by modifying our parameter values, but we were unable to identically reproduce the output of <code>scikit-learn</code>. Overall, our results indicate that for this problem, regularization does not lead to improved performance on the testing data, although it may facilitate interpretation of coefficients.</p>
</section>
</section>
</section>
<section id="discussion-of-linear-regression" class="level2">
<h2 class="anchored" data-anchor-id="discussion-of-linear-regression">Discussion of Linear Regression</h2>
<p>In linear regression, a major assumption is that all observations are independent of each other. However, when working with spatial data, nearby observations are often similar, such that observations are not independent if they are in close proximity to each other. In order to determine whether our model suffers from such spatial dependence, we will fit a linear regression model on the entire dataset and produce a map of our model’s residuals. We opt for linear regression without regularization due to its higher performance in the work above.</p>
<div id="cell-101" class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="co"># convert to torch tensors</span></span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a><span class="co"># add column of ones for y-intercept</span></span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a>X_torch <span class="op">=</span> torch.cat((torch.tensor(X.values), torch.ones((X.shape[<span class="dv">0</span>], <span class="dv">1</span>))), <span class="dv">1</span>)</span>
<span id="cb81-4"><a href="#cb81-4" aria-hidden="true" tabindex="-1"></a>y_torch <span class="op">=</span> torch.tensor(y.values)</span>
<span id="cb81-5"><a href="#cb81-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-6"><a href="#cb81-6" aria-hidden="true" tabindex="-1"></a><span class="co"># fit linear regression model</span></span>
<span id="cb81-7"><a href="#cb81-7" aria-hidden="true" tabindex="-1"></a>LR_full <span class="op">=</span> LinearRegress()</span>
<span id="cb81-8"><a href="#cb81-8" aria-hidden="true" tabindex="-1"></a>opt_full <span class="op">=</span> GradientDescentOptimizer(LR_full)</span>
<span id="cb81-9"><a href="#cb81-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-10"><a href="#cb81-10" aria-hidden="true" tabindex="-1"></a><span class="co"># fit model</span></span>
<span id="cb81-11"><a href="#cb81-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">500000</span>): </span>
<span id="cb81-12"><a href="#cb81-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># update model</span></span>
<span id="cb81-13"><a href="#cb81-13" aria-hidden="true" tabindex="-1"></a>    opt_full.step(X_torch, y_torch, alpha <span class="op">=</span> <span class="fl">0.01</span>)</span>
<span id="cb81-14"><a href="#cb81-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-15"><a href="#cb81-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># calculate and record loss</span></span>
<span id="cb81-16"><a href="#cb81-16" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> LR_full.loss(X_torch, y_torch) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-102" class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate residuals</span></span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a>resid <span class="op">=</span> (y_torch <span class="op">-</span> LR_full.pred(X_torch))</span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true" tabindex="-1"></a><span class="co"># add residual column to tracts</span></span>
<span id="cb82-5"><a href="#cb82-5" aria-hidden="true" tabindex="-1"></a>tracts[<span class="st">"resid"</span>] <span class="op">=</span> resid</span>
<span id="cb82-6"><a href="#cb82-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-7"><a href="#cb82-7" aria-hidden="true" tabindex="-1"></a><span class="co"># specify that color ramp should be centered at 0</span></span>
<span id="cb82-8"><a href="#cb82-8" aria-hidden="true" tabindex="-1"></a>divnorm <span class="op">=</span> TwoSlopeNorm(vmin<span class="op">=-</span><span class="dv">3000</span>, vcenter<span class="op">=</span><span class="fl">0.</span>, vmax <span class="op">=</span> <span class="dv">3000</span>)</span>
<span id="cb82-9"><a href="#cb82-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-10"><a href="#cb82-10" aria-hidden="true" tabindex="-1"></a><span class="co"># create map</span></span>
<span id="cb82-11"><a href="#cb82-11" aria-hidden="true" tabindex="-1"></a>resid_map <span class="op">=</span> tracts.plot(<span class="st">"resid"</span>, legend <span class="op">=</span> <span class="va">True</span>, cmap <span class="op">=</span> <span class="st">"seismic"</span>, norm <span class="op">=</span> divnorm, figsize <span class="op">=</span> (<span class="dv">8</span>,<span class="dv">8</span>))</span>
<span id="cb82-12"><a href="#cb82-12" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Residual Map"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="final_project_files/figure-html/cell-49-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>In an ideal scenario with spatially independent observations, the values of residuals would be distributed randomly throughout the map. However, with clear clusters of red and blue, our model visually appears to be making similar errors in nearby places. In other words, our residuals suffer from spatial autocorrelation. This may occur because the population density in one tract influences the population density in another tract; similarly, the landcover in one tract may influence the population density in a neighboring tract. Fortunately, there exists an entire field of spatial statistics dedicated to addressing issues of spatial autocorrelation. In the following section, we will employ one technique, known as <em>spatial lag regression</em>, in order to account for spatial dependence and hopefully improve our results. Before continuing to our section on spatial autoregression, we first perform cross-validation on linear regression and report the average root mean squared error (RMSE) in order to compare our results to our autoregressive results. We will opt for <code>scikit-learn</code>’s linear regression class since it is faster and achieves identical results to ours.</p>
<div id="cell-104" class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="co"># define model</span></span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>LR <span class="op">=</span> LinearRegression() </span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-4"><a href="#cb83-4" aria-hidden="true" tabindex="-1"></a><span class="co"># define scoring function</span></span>
<span id="cb83-5"><a href="#cb83-5" aria-hidden="true" tabindex="-1"></a><span class="co"># this is just required in order to use scikit-learn's cross_val_score function</span></span>
<span id="cb83-6"><a href="#cb83-6" aria-hidden="true" tabindex="-1"></a><span class="co"># basically they multiply the MSE by -1, so we need to account for that afterwards</span></span>
<span id="cb83-7"><a href="#cb83-7" aria-hidden="true" tabindex="-1"></a>mse_score <span class="op">=</span> make_scorer(mean_squared_error, greater_is_better <span class="op">=</span> <span class="va">False</span>)</span>
<span id="cb83-8"><a href="#cb83-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-9"><a href="#cb83-9" aria-hidden="true" tabindex="-1"></a><span class="co"># cross validation</span></span>
<span id="cb83-10"><a href="#cb83-10" aria-hidden="true" tabindex="-1"></a>cv_scores_LR <span class="op">=</span> cross_val_score(estimator <span class="op">=</span> LR, X <span class="op">=</span> X, y <span class="op">=</span> y, scoring <span class="op">=</span> mse_score, cv <span class="op">=</span> <span class="dv">4</span>)</span>
<span id="cb83-11"><a href="#cb83-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-12"><a href="#cb83-12" aria-hidden="true" tabindex="-1"></a><span class="co"># compute average RMSE</span></span>
<span id="cb83-13"><a href="#cb83-13" aria-hidden="true" tabindex="-1"></a>np.sqrt(<span class="op">-</span><span class="dv">1</span><span class="op">*</span>cv_scores_LR).mean()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="49">
<pre><code>503.0545511056982</code></pre>
</div>
</div>
<p>With regular linear regression, we have achieved an average cross-validation RMSE of <span class="math inline">\(503\)</span> people per square kilometer. Let’s see if accounting for space can improve our results!</p>
</section>
</section>
<section id="spatial-autoregression" class="level1">
<h1>Spatial Autoregression</h1>
<p>In previous section, we predicted the population denisty of tracts, considering each tract as independent from each other. However, in reality, the population densisty of each tract is dependent on its neighbors. For example, in urban regions, high density tracts are typically surrounded by high density tracts (the opposite holds true in rural area tracts). The first law of geography states that “everything is related to everything else, but near things are more related than distant things.” Spatial autoregression model considers the features of the surrounding objects as part of the prediction. In this section, we are going to implement spatial autoregressive model on predicting the density data.</p>
<section id="data-processing-and-exploration" class="level2">
<h2 class="anchored" data-anchor-id="data-processing-and-exploration">Data Processing and Exploration</h2>
<p>In this spatial autoregression model, we adopt queen criterion to construct spatial continuity weight matrix. The queen criterion defines neighbors as spatial units sharing a common edge or a common vertex. This means that in our model, we will add the features and characteristics of the neighboring tracts as part of the prediction variables.</p>
<p>To find the weight matrix, we need to introduce geometry to our dataset. Here, I am merging the csv file to a shapefile and convert the merged data to a GeoDataFrame format. Later, I calculate the queen spatial continuity matrix using the <code>libpysal</code> pacakge. Using the spatial weight continuity matrix, we can then calculate the spatial lag data of population density, which is the mean population density of the neighboring tracts.</p>
<div id="cell-107" class="cell" data-metadata="{}" data-execution_count="5">
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="co"># import shapefile</span></span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a><span class="co"># need separate shapefile because the one form pygris didn't cooperate with the weights matrix functions</span></span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.read_csv(<span class="st">"../data/combined_data.csv"</span>)</span>
<span id="cb85-4"><a href="#cb85-4" aria-hidden="true" tabindex="-1"></a>gdf <span class="op">=</span> gpd.read_file(<span class="st">'../data/tl_2016_09_tract.shp'</span>)</span>
<span id="cb85-5"><a href="#cb85-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-6"><a href="#cb85-6" aria-hidden="true" tabindex="-1"></a><span class="co"># create merge columns</span></span>
<span id="cb85-7"><a href="#cb85-7" aria-hidden="true" tabindex="-1"></a>gdf[<span class="st">'TRACTCE'</span>] <span class="op">=</span> gdf[<span class="st">'TRACTCE'</span>].astype(<span class="bu">int</span>)</span>
<span id="cb85-8"><a href="#cb85-8" aria-hidden="true" tabindex="-1"></a>data[<span class="st">'TRACTCE'</span>] <span class="op">=</span> data[<span class="st">'TRACTCE'</span>].astype(<span class="bu">int</span>)</span>
<span id="cb85-9"><a href="#cb85-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-10"><a href="#cb85-10" aria-hidden="true" tabindex="-1"></a><span class="co"># merge csv with shapfile using TRACTCE</span></span>
<span id="cb85-11"><a href="#cb85-11" aria-hidden="true" tabindex="-1"></a>merged_gdf <span class="op">=</span> gdf.merge(data, on<span class="op">=</span><span class="st">'TRACTCE'</span>, how<span class="op">=</span><span class="st">'left'</span>)</span>
<span id="cb85-12"><a href="#cb85-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-13"><a href="#cb85-13" aria-hidden="true" tabindex="-1"></a><span class="co"># make merged_gdf into geo dataframe</span></span>
<span id="cb85-14"><a href="#cb85-14" aria-hidden="true" tabindex="-1"></a>merged_gdf <span class="op">=</span> gpd.GeoDataFrame(merged_gdf)</span>
<span id="cb85-15"><a href="#cb85-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-16"><a href="#cb85-16" aria-hidden="true" tabindex="-1"></a><span class="co"># drop out all rows that have no population density</span></span>
<span id="cb85-17"><a href="#cb85-17" aria-hidden="true" tabindex="-1"></a>merged_gdf <span class="op">=</span> merged_gdf.dropna(subset<span class="op">=</span>[<span class="st">'PopDensity'</span>], axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb85-18"><a href="#cb85-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-19"><a href="#cb85-19" aria-hidden="true" tabindex="-1"></a><span class="co"># clean tracts that have truncated data on population density</span></span>
<span id="cb85-20"><a href="#cb85-20" aria-hidden="true" tabindex="-1"></a>merged_gdf <span class="op">=</span> merged_gdf[merged_gdf[<span class="st">'PopDensity'</span>] <span class="op">!=</span> <span class="dv">0</span>]</span>
<span id="cb85-21"><a href="#cb85-21" aria-hidden="true" tabindex="-1"></a>merged_gdf <span class="op">=</span> merged_gdf[merged_gdf[<span class="st">'TRACTCE'</span>] <span class="op">!=</span> <span class="dv">194202</span>]</span>
<span id="cb85-22"><a href="#cb85-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-23"><a href="#cb85-23" aria-hidden="true" tabindex="-1"></a><span class="co"># define the geometry_x column to be the geometry feature </span></span>
<span id="cb85-24"><a href="#cb85-24" aria-hidden="true" tabindex="-1"></a>merged_gdf.set_geometry(<span class="st">"geometry_x"</span>, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb85-25"><a href="#cb85-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-26"><a href="#cb85-26" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate Queen's neighbor weights for each tracts</span></span>
<span id="cb85-27"><a href="#cb85-27" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> lp.weights.Queen.from_dataframe(merged_gdf)</span>
<span id="cb85-28"><a href="#cb85-28" aria-hidden="true" tabindex="-1"></a>w.transform <span class="op">=</span> <span class="st">'R'</span></span>
<span id="cb85-29"><a href="#cb85-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-30"><a href="#cb85-30" aria-hidden="true" tabindex="-1"></a><span class="co"># compute spatial lag of population density</span></span>
<span id="cb85-31"><a href="#cb85-31" aria-hidden="true" tabindex="-1"></a>merged_gdf[<span class="st">'spatial_lag_PopDens'</span>] <span class="op">=</span> lp.weights.lag_spatial(w, merged_gdf[<span class="st">'PopDensity'</span>])</span>
<span id="cb85-32"><a href="#cb85-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-33"><a href="#cb85-33" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate the mean pop density of each tract's neighbors</span></span>
<span id="cb85-34"><a href="#cb85-34" aria-hidden="true" tabindex="-1"></a><span class="co">#merged_gdf['avg_neighbor_density'] = merged_gdf.groupby('TRACTCE')['spatial_lag'].transform('mean')</span></span>
<span id="cb85-35"><a href="#cb85-35" aria-hidden="true" tabindex="-1"></a>merged_gdf[<span class="st">'PopDensity'</span>] <span class="op">=</span> merged_gdf[<span class="st">'PopDensity'</span>].astype(<span class="bu">float</span>)</span>
<span id="cb85-36"><a href="#cb85-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-37"><a href="#cb85-37" aria-hidden="true" tabindex="-1"></a><span class="co"># download merged_gdf to csv file</span></span>
<span id="cb85-38"><a href="#cb85-38" aria-hidden="true" tabindex="-1"></a>merged_gdf.to_csv(<span class="st">'../data/merged_gdf.csv'</span>, index<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/tmp/ipykernel_18572/2255761594.py:27: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning
  w = lp.weights.Queen.from_dataframe(merged_gdf)</code></pre>
</div>
</div>
<p>Next, we want to perform a spatial autocorrelation evaluation using Global Moran’s I index. This evaluation assesses the spatial distribution characteristic of the entire region. We plot the scatter plot between the population denisty and mean population denisty of tract’s neighbors. The Global Moran’s I index, if we do not delve into its mathematical details, is the slope of the best fit line between these two numbers. In our case, we calculated the Moran’s I index to be 0.6. Together with the distribution of the scatter plot, we believe that population density of the neighboring tracts are dependent. We also want to inspect the spatial association at a local scale. The color of each tract is based on its own population density and the population density of its surrounding tracts.</p>
<p><a href="https://geographicdata.science/book/notebooks/07_local_autocorrelation.html">Moran’s Scatterplot</a> has four categories: High-High, High-Low, Low-High, Low-Low. High/low before the dash means whether the tract has a populuation density that is higher/lower than the mean overall population density. High/low after the dash means whether the tract’s neighbors population denisty is above/below the average population density. After categorization, we map the tracts to inspect the distribution of the tracts’ categories. We find that High-High tracts are usually in urban areas, Low-High tracts are usually suburbs, High-Low tracts are typically towns in the rural area, and Low-Low are rural tracts. Therefore, we believe that by taking into account the characteristics of the target tract’s neighboring tract, we are able to predict population density better than ordinary least square regression.</p>
<div id="cell-109" class="cell" data-metadata="{}" data-execution_count="6">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="co"># read data</span></span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>merged_csv_moran <span class="op">=</span> pd.read_csv(<span class="st">"../data/merged_gdf.csv"</span>, usecols<span class="op">=</span>[<span class="st">'PopDensity'</span>, <span class="st">'spatial_lag_PopDens'</span>, <span class="st">"Geo_NAME"</span>]).dropna()</span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract x and y columns from the DataFrame</span></span>
<span id="cb87-5"><a href="#cb87-5" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> merged_csv_moran[<span class="st">'PopDensity'</span>].values.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)  <span class="co"># Reshape to make it a 2D array for scikit-learn</span></span>
<span id="cb87-6"><a href="#cb87-6" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> merged_csv_moran[<span class="st">'spatial_lag_PopDens'</span>].values</span>
<span id="cb87-7"><a href="#cb87-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-8"><a href="#cb87-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the average for 'spatial_lag_PopDens' and 'PopDensity'</span></span>
<span id="cb87-9"><a href="#cb87-9" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> merged_csv_moran[<span class="st">'spatial_lag_PopDens'</span>].mean()</span>
<span id="cb87-10"><a href="#cb87-10" aria-hidden="true" tabindex="-1"></a>q <span class="op">=</span> merged_csv_moran[<span class="st">'PopDensity'</span>].mean()</span>
<span id="cb87-11"><a href="#cb87-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-12"><a href="#cb87-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Categorize the rows based on conditions</span></span>
<span id="cb87-13"><a href="#cb87-13" aria-hidden="true" tabindex="-1"></a>merged_csv_moran[<span class="st">'category'</span>] <span class="op">=</span> <span class="dv">0</span>  <span class="co"># Initialize category column</span></span>
<span id="cb87-14"><a href="#cb87-14" aria-hidden="true" tabindex="-1"></a>merged_csv_moran.loc[(merged_csv_moran[<span class="st">'spatial_lag_PopDens'</span>] <span class="op">&gt;=</span> p) <span class="op">&amp;</span> (merged_csv_moran[<span class="st">'PopDensity'</span>] <span class="op">&gt;=</span> q), <span class="st">'category'</span>] <span class="op">=</span> <span class="st">'High-High'</span></span>
<span id="cb87-15"><a href="#cb87-15" aria-hidden="true" tabindex="-1"></a>merged_csv_moran.loc[(merged_csv_moran[<span class="st">'spatial_lag_PopDens'</span>] <span class="op">&gt;=</span> p) <span class="op">&amp;</span> (merged_csv_moran[<span class="st">'PopDensity'</span>] <span class="op">&lt;</span> q), <span class="st">'category'</span>] <span class="op">=</span> <span class="st">'Low-High'</span></span>
<span id="cb87-16"><a href="#cb87-16" aria-hidden="true" tabindex="-1"></a>merged_csv_moran.loc[(merged_csv_moran[<span class="st">'spatial_lag_PopDens'</span>] <span class="op">&lt;</span> p) <span class="op">&amp;</span> (merged_csv_moran[<span class="st">'PopDensity'</span>] <span class="op">&gt;=</span> q), <span class="st">'category'</span>] <span class="op">=</span> <span class="st">'High-Low'</span></span>
<span id="cb87-17"><a href="#cb87-17" aria-hidden="true" tabindex="-1"></a>merged_csv_moran.loc[(merged_csv_moran[<span class="st">'spatial_lag_PopDens'</span>] <span class="op">&lt;</span> p) <span class="op">&amp;</span> (merged_csv_moran[<span class="st">'PopDensity'</span>] <span class="op">&lt;</span> q), <span class="st">'category'</span>] <span class="op">=</span> <span class="st">'Low-Low'</span></span>
<span id="cb87-18"><a href="#cb87-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-19"><a href="#cb87-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the average for 'spatial_lag_PopDens' and 'PopDensity'</span></span>
<span id="cb87-20"><a href="#cb87-20" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> merged_csv_moran[<span class="st">'spatial_lag_PopDens'</span>].mean()</span>
<span id="cb87-21"><a href="#cb87-21" aria-hidden="true" tabindex="-1"></a>q <span class="op">=</span> merged_csv_moran[<span class="st">'PopDensity'</span>].mean()</span>
<span id="cb87-22"><a href="#cb87-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-23"><a href="#cb87-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Define custom colors for categories</span></span>
<span id="cb87-24"><a href="#cb87-24" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> {<span class="st">'High-High'</span>: <span class="st">'#F47E3E'</span>, <span class="st">'Low-Low'</span>: <span class="st">'#0FA3B1'</span>, <span class="st">'Low-High'</span>: <span class="st">'#D9E5D6'</span>, <span class="st">'High-Low'</span>: <span class="st">'#DCC156'</span>}</span>
<span id="cb87-25"><a href="#cb87-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-26"><a href="#cb87-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a scatter plot of x vs y</span></span>
<span id="cb87-27"><a href="#cb87-27" aria-hidden="true" tabindex="-1"></a>scatter <span class="op">=</span> plt.scatter(x, y, color<span class="op">=</span>merged_csv_moran[<span class="st">'category'</span>].<span class="bu">map</span>(colors))</span>
<span id="cb87-28"><a href="#cb87-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-29"><a href="#cb87-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a linear regression model</span></span>
<span id="cb87-30"><a href="#cb87-30" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LinearRegression()</span>
<span id="cb87-31"><a href="#cb87-31" aria-hidden="true" tabindex="-1"></a>model.fit(x, y)</span>
<span id="cb87-32"><a href="#cb87-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-33"><a href="#cb87-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the slope and intercept of the fitted line</span></span>
<span id="cb87-34"><a href="#cb87-34" aria-hidden="true" tabindex="-1"></a>slope <span class="op">=</span> model.coef_[<span class="dv">0</span>]</span>
<span id="cb87-35"><a href="#cb87-35" aria-hidden="true" tabindex="-1"></a>intercept <span class="op">=</span> model.intercept_</span>
<span id="cb87-36"><a href="#cb87-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-37"><a href="#cb87-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the fitted line</span></span>
<span id="cb87-38"><a href="#cb87-38" aria-hidden="true" tabindex="-1"></a>plt.plot(x, model.predict(x), color<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="ss">f'Linear Regression (y = </span><span class="sc">{</span>slope<span class="sc">:.2f}</span><span class="ss">x + </span><span class="sc">{</span>intercept<span class="sc">:.2f}</span><span class="ss">)'</span>)</span>
<span id="cb87-39"><a href="#cb87-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-40"><a href="#cb87-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Add labels and title</span></span>
<span id="cb87-41"><a href="#cb87-41" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Population Density'</span>)</span>
<span id="cb87-42"><a href="#cb87-42" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Spatial Lag Density'</span>)</span>
<span id="cb87-43"><a href="#cb87-43" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Moran's I = 0.60"</span>)</span>
<span id="cb87-44"><a href="#cb87-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-45"><a href="#cb87-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Create legend entries manually</span></span>
<span id="cb87-46"><a href="#cb87-46" aria-hidden="true" tabindex="-1"></a>legend_patches <span class="op">=</span> [</span>
<span id="cb87-47"><a href="#cb87-47" aria-hidden="true" tabindex="-1"></a>    Patch(color<span class="op">=</span>color, label<span class="op">=</span>label) <span class="cf">for</span> label, color <span class="kw">in</span> colors.items()</span>
<span id="cb87-48"><a href="#cb87-48" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb87-49"><a href="#cb87-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-50"><a href="#cb87-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Add the legend with custom entries and regression equation</span></span>
<span id="cb87-51"><a href="#cb87-51" aria-hidden="true" tabindex="-1"></a>plt.legend(handles<span class="op">=</span>legend_patches <span class="op">+</span> [scatter, plt.Line2D([<span class="dv">0</span>], [<span class="dv">0</span>], color<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="ss">f'(y = </span><span class="sc">{</span>slope<span class="sc">:.2f}</span><span class="ss">x + </span><span class="sc">{</span>intercept<span class="sc">:.2f}</span><span class="ss">)'</span>)])</span>
<span id="cb87-52"><a href="#cb87-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-53"><a href="#cb87-53" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw horizontal and vertical dashed line at y = p</span></span>
<span id="cb87-54"><a href="#cb87-54" aria-hidden="true" tabindex="-1"></a>plt.axhline(y<span class="op">=</span>p, color<span class="op">=</span><span class="st">'gray'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>)</span>
<span id="cb87-55"><a href="#cb87-55" aria-hidden="true" tabindex="-1"></a>plt.axvline(x<span class="op">=</span>q, color<span class="op">=</span><span class="st">'gray'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>)</span>
<span id="cb87-56"><a href="#cb87-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-57"><a href="#cb87-57" aria-hidden="true" tabindex="-1"></a><span class="co"># Show plot</span></span>
<span id="cb87-58"><a href="#cb87-58" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/tmp/ipykernel_18572/4162410205.py:14: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'High-High' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.
  merged_csv_moran.loc[(merged_csv_moran['spatial_lag_PopDens'] &gt;= p) &amp; (merged_csv_moran['PopDensity'] &gt;= q), 'category'] = 'High-High'
/tmp/ipykernel_18572/4162410205.py:51: MatplotlibDeprecationWarning: An artist whose label starts with an underscore was passed to legend(); such artists will no longer be ignored in the future.  To suppress this warning, explicitly filter out such artists, e.g. with `[art for art in artists if not art.get_label().startswith('_')]`.
  plt.legend(handles=legend_patches + [scatter, plt.Line2D([0], [0], color='red', label=f'(y = {slope:.2f}x + {intercept:.2f})')])</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="final_project_files/figure-html/cell-52-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-110" class="cell" data-metadata="{}" data-execution_count="8">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the average for 'spatial_lag_PopDens' and 'PopDensity'</span></span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> merged_gdf[<span class="st">'spatial_lag_PopDens'</span>].mean()</span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a>q <span class="op">=</span> merged_gdf[<span class="st">'PopDensity'</span>].mean()</span>
<span id="cb89-4"><a href="#cb89-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-5"><a href="#cb89-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Categorize the rows based on conditions</span></span>
<span id="cb89-6"><a href="#cb89-6" aria-hidden="true" tabindex="-1"></a>merged_gdf[<span class="st">'category'</span>] <span class="op">=</span> <span class="dv">0</span>  <span class="co"># Initialize category column</span></span>
<span id="cb89-7"><a href="#cb89-7" aria-hidden="true" tabindex="-1"></a>merged_gdf.loc[(merged_gdf[<span class="st">'spatial_lag_PopDens'</span>] <span class="op">&gt;=</span> p) <span class="op">&amp;</span> (merged_gdf[<span class="st">'PopDensity'</span>] <span class="op">&gt;=</span> q), <span class="st">'category'</span>] <span class="op">=</span> <span class="st">'High-High'</span></span>
<span id="cb89-8"><a href="#cb89-8" aria-hidden="true" tabindex="-1"></a>merged_gdf.loc[(merged_gdf[<span class="st">'spatial_lag_PopDens'</span>] <span class="op">&gt;=</span> p) <span class="op">&amp;</span> (merged_gdf[<span class="st">'PopDensity'</span>] <span class="op">&lt;</span> q), <span class="st">'category'</span>] <span class="op">=</span> <span class="st">'Low-High'</span></span>
<span id="cb89-9"><a href="#cb89-9" aria-hidden="true" tabindex="-1"></a>merged_gdf.loc[(merged_gdf[<span class="st">'spatial_lag_PopDens'</span>] <span class="op">&lt;</span> p) <span class="op">&amp;</span> (merged_gdf[<span class="st">'PopDensity'</span>] <span class="op">&gt;=</span> q), <span class="st">'category'</span>] <span class="op">=</span> <span class="st">'High-Low'</span></span>
<span id="cb89-10"><a href="#cb89-10" aria-hidden="true" tabindex="-1"></a>merged_gdf.loc[(merged_gdf[<span class="st">'spatial_lag_PopDens'</span>] <span class="op">&lt;</span> p) <span class="op">&amp;</span> (merged_gdf[<span class="st">'PopDensity'</span>] <span class="op">&lt;</span> q), <span class="st">'category'</span>] <span class="op">=</span> <span class="st">'Low-Low'</span></span>
<span id="cb89-11"><a href="#cb89-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-12"><a href="#cb89-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Define custom colors for categories</span></span>
<span id="cb89-13"><a href="#cb89-13" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> {<span class="st">'High-High'</span>: <span class="st">'#F47E3E'</span>, <span class="st">'Low-Low'</span>: <span class="st">'#0FA3B1'</span>, <span class="st">'Low-High'</span>: <span class="st">'#D9E5D6'</span>, <span class="st">'High-Low'</span>: <span class="st">'#DCC156'</span>}</span>
<span id="cb89-14"><a href="#cb89-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-15"><a href="#cb89-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the map using custom colors</span></span>
<span id="cb89-16"><a href="#cb89-16" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb89-17"><a href="#cb89-17" aria-hidden="true" tabindex="-1"></a>merged_gdf.plot(column<span class="op">=</span><span class="st">'category'</span>, ax<span class="op">=</span>ax, color<span class="op">=</span>merged_gdf[<span class="st">'category'</span>].<span class="bu">map</span>(colors), legend<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb89-18"><a href="#cb89-18" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Map of Moran Scatterplot Quadrants'</span>)</span>
<span id="cb89-19"><a href="#cb89-19" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/tmp/ipykernel_18572/3545356962.py:7: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'High-High' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.
  merged_gdf.loc[(merged_gdf['spatial_lag_PopDens'] &gt;= p) &amp; (merged_gdf['PopDensity'] &gt;= q), 'category'] = 'High-High'
/tmp/ipykernel_18572/3545356962.py:17: UserWarning: Only specify one of 'column' or 'color'. Using 'color'.
  merged_gdf.plot(column='category', ax=ax, color=merged_gdf['category'].map(colors), legend=True)</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="final_project_files/figure-html/cell-53-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Instead of using all possible land cover types, we are going to use land cover types that are more common among all tracts in CT for density prediction. The land cover types we selected are the same as the ones in linear regression section.</p>
<div id="cell-112" class="cell" data-metadata="{}" data-execution_count="9">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="co"># All landcover types</span></span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a>all_landcover <span class="op">=</span> [<span class="st">'2'</span>, <span class="st">'5'</span>, <span class="st">'8'</span>, <span class="st">'11'</span>, <span class="st">'12'</span>, <span class="st">'13'</span>, <span class="st">'14'</span>, <span class="st">'15'</span>, <span class="st">'17'</span>, <span class="st">'18'</span>, <span class="st">'19'</span>, <span class="st">'20'</span>, <span class="st">'21'</span>, <span class="st">'22'</span>, <span class="st">'7'</span>, <span class="st">'6'</span>, <span class="st">'0'</span>, <span class="st">'23'</span>]</span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a>all_landcover_pct <span class="op">=</span> [<span class="st">'2pct'</span>, <span class="st">'5pct'</span>, <span class="st">'8pct'</span>, <span class="st">'11pct'</span>, <span class="st">'12pct'</span>, <span class="st">'13pct'</span>, <span class="st">'14pct'</span>, <span class="st">'15pct'</span>, <span class="st">'17pct'</span>, <span class="st">'18pct'</span>, <span class="st">'19pct'</span>, <span class="st">'20pct'</span>, <span class="st">'21pct'</span>, <span class="st">'22pct'</span>, <span class="st">'7pct'</span>, <span class="st">'6pct'</span>, <span class="st">'0pct'</span>, <span class="st">'23pct'</span>]</span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-5"><a href="#cb91-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Select landcover types</span></span>
<span id="cb91-6"><a href="#cb91-6" aria-hidden="true" tabindex="-1"></a>landcover_types <span class="op">=</span> [<span class="st">'2'</span>, <span class="st">'5'</span>, <span class="st">'11'</span>, <span class="st">'12'</span>, <span class="st">'8'</span>, <span class="st">'13'</span>, <span class="st">'14'</span>, <span class="st">'15'</span>, <span class="st">'20'</span>, <span class="st">'21'</span>] <span class="co">#, '22', '7', '8', '13', '14', '15', '20', '21'</span></span>
<span id="cb91-7"><a href="#cb91-7" aria-hidden="true" tabindex="-1"></a>landcover_pct <span class="op">=</span> [<span class="st">'2pct'</span>, <span class="st">'5pct'</span>, <span class="st">'11pct'</span>, <span class="st">'12pct'</span>, <span class="st">'8pct'</span>, <span class="st">'13pct'</span>, <span class="st">'14pct'</span>, <span class="st">'15pct'</span>, <span class="st">'20pct'</span>, <span class="st">'21pct'</span>] <span class="co"># , '22pct', '7pct', '8pct', '13pct', '14pct', '15pct', '20pct', '21pct'</span></span>
<span id="cb91-8"><a href="#cb91-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-9"><a href="#cb91-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Merge them into our data</span></span>
<span id="cb91-10"><a href="#cb91-10" aria-hidden="true" tabindex="-1"></a>merged_gdf[<span class="st">'sum'</span>] <span class="op">=</span> merged_gdf[all_landcover].<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb91-11"><a href="#cb91-11" aria-hidden="true" tabindex="-1"></a>merged_gdf[all_landcover_pct] <span class="op">=</span> merged_gdf[all_landcover].div(merged_gdf[<span class="st">'sum'</span>], axis<span class="op">=</span><span class="dv">0</span>).multiply(<span class="dv">100</span>).astype(<span class="bu">float</span>)</span>
<span id="cb91-12"><a href="#cb91-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-13"><a href="#cb91-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Download merged_gdf to csv file optionally </span></span>
<span id="cb91-14"><a href="#cb91-14" aria-hidden="true" tabindex="-1"></a><span class="co">#merged_gdf.to_csv('merged_gdf_saved.csv', index=False)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="spatial-lag-regression" class="level2">
<h2 class="anchored" data-anchor-id="spatial-lag-regression">Spatial Lag Regression</h2>
<section id="endogenous-vs.-exogenous-whats-the-difference" class="level3">
<h3 class="anchored" data-anchor-id="endogenous-vs.-exogenous-whats-the-difference">Endogenous vs.&nbsp;Exogenous: What’s the Difference?</h3>
<p>There are two types of spatially lagged regression models. The first one is <strong>spatially lagged endogenous regression model</strong>. The endogenous model includes the spatial lagged value of the target variable as one of the explanatory variables for regression. In our case, the population density of a tract’s neighbor is part of the variables we use to predict the population density of the tract.</p>
<p>The second type of spatially lagged regression model is <strong>spatially lagged exogenous regression model</strong>. Instead of taking into account the population density, our target variable, of the neighboring tracts, the exogenous model considers the explanatory variables of the tract’s surroundings. In our case, the spatially lagged exogenous model adds neighbors’ land type information to the model. We will calculate the spatial lagged value of each land cover type for all tracts and include them as part of the predictor variables.</p>
<p>We first fit both models to the entirety of CT and map their residuals on each tract. First, we fit the endogenous model.</p>
<div id="cell-114" class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Endogenous model: consider spatial lag population denisty</span></span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>predictor <span class="op">=</span> landcover_pct <span class="op">+</span> [<span class="st">'spatial_lag_PopDens'</span>]</span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Get explanatory variables and target variable</span></span>
<span id="cb92-5"><a href="#cb92-5" aria-hidden="true" tabindex="-1"></a>X_merged_gdf <span class="op">=</span> merged_gdf[predictor].values</span>
<span id="cb92-6"><a href="#cb92-6" aria-hidden="true" tabindex="-1"></a>y_merged_gdf <span class="op">=</span> merged_gdf[<span class="st">'PopDensity'</span>].values.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb92-7"><a href="#cb92-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-8"><a href="#cb92-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Create, fit, and predict with Linear Regression</span></span>
<span id="cb92-9"><a href="#cb92-9" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LinearRegression()</span>
<span id="cb92-10"><a href="#cb92-10" aria-hidden="true" tabindex="-1"></a>model.fit(X_merged_gdf, y_merged_gdf)</span>
<span id="cb92-11"><a href="#cb92-11" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> model.predict(X_merged_gdf)</span>
<span id="cb92-12"><a href="#cb92-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-13"><a href="#cb92-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate residuals </span></span>
<span id="cb92-14"><a href="#cb92-14" aria-hidden="true" tabindex="-1"></a>residuals <span class="op">=</span> y_merged_gdf <span class="op">-</span> y_pred</span>
<span id="cb92-15"><a href="#cb92-15" aria-hidden="true" tabindex="-1"></a>merged_gdf[<span class="st">'residuals'</span>] <span class="op">=</span> residuals</span>
<span id="cb92-16"><a href="#cb92-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-17"><a href="#cb92-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove Spatial lag so that our Exogenous model does not take this into account</span></span>
<span id="cb92-18"><a href="#cb92-18" aria-hidden="true" tabindex="-1"></a>merged_gdf.drop(columns<span class="op">=</span>[<span class="st">'spatial_lag_PopDens'</span>], inplace<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Next, we fit the exogenous model.</p>
<div id="cell-116" class="cell" data-execution_count="58">
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Exogenous model: consider</span></span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a>exo_predictor <span class="op">=</span> landcover_pct <span class="op">+</span> [<span class="st">'lag_2pct'</span>, <span class="st">'lag_5pct'</span>, <span class="st">'lag_11pct'</span>, <span class="st">'lag_12pct'</span>, <span class="st">'lag_8pct'</span>, <span class="st">'lag_13pct'</span>, <span class="st">'lag_14pct'</span>, <span class="st">'lag_15pct'</span>, <span class="st">'lag_20pct'</span>, <span class="st">'lag_21pct'</span>] </span>
<span id="cb93-3"><a href="#cb93-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-4"><a href="#cb93-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(landcover_pct)):</span>
<span id="cb93-5"><a href="#cb93-5" aria-hidden="true" tabindex="-1"></a>        merged_gdf[<span class="st">'lag_'</span> <span class="op">+</span> landcover_pct[i]] <span class="op">=</span> lp.weights.lag_spatial(w, merged_gdf[landcover_pct[i]])</span>
<span id="cb93-6"><a href="#cb93-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-7"><a href="#cb93-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Get explanatory variables and target variable</span></span>
<span id="cb93-8"><a href="#cb93-8" aria-hidden="true" tabindex="-1"></a>X_merged_gdf_exo <span class="op">=</span> merged_gdf[exo_predictor].values</span>
<span id="cb93-9"><a href="#cb93-9" aria-hidden="true" tabindex="-1"></a>y_merged_gdf_exo <span class="op">=</span> merged_gdf[<span class="st">'PopDensity'</span>].values.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb93-10"><a href="#cb93-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-11"><a href="#cb93-11" aria-hidden="true" tabindex="-1"></a><span class="co">#Create, fit, and predict with Linear Regression</span></span>
<span id="cb93-12"><a href="#cb93-12" aria-hidden="true" tabindex="-1"></a>model_exo <span class="op">=</span> LinearRegression()</span>
<span id="cb93-13"><a href="#cb93-13" aria-hidden="true" tabindex="-1"></a>model_exo.fit(X_merged_gdf_exo, y_merged_gdf_exo)</span>
<span id="cb93-14"><a href="#cb93-14" aria-hidden="true" tabindex="-1"></a>y_pred_exo <span class="op">=</span> model_exo.predict(X_merged_gdf_exo)</span>
<span id="cb93-15"><a href="#cb93-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-16"><a href="#cb93-16" aria-hidden="true" tabindex="-1"></a><span class="co">#Calculate Residuals and make new column</span></span>
<span id="cb93-17"><a href="#cb93-17" aria-hidden="true" tabindex="-1"></a>residuals_exo <span class="op">=</span> y_merged_gdf_exo <span class="op">-</span> y_pred_exo</span>
<span id="cb93-18"><a href="#cb93-18" aria-hidden="true" tabindex="-1"></a>merged_gdf[<span class="st">'residuals_exo'</span>] <span class="op">=</span> residuals_exo</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now, we visualize the map of residuals for both models.</p>
<div id="cell-118" class="cell" data-execution_count="60">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the colors for the custom colormap</span></span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> [(<span class="dv">0</span>, <span class="st">'brown'</span>), (<span class="fl">0.5</span>, <span class="st">'white'</span>), (<span class="dv">1</span>, <span class="st">'green'</span>)]  <span class="co"># Position 0 is brown, position 0.5 is white, position 1 is green</span></span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-4"><a href="#cb94-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the colormap</span></span>
<span id="cb94-5"><a href="#cb94-5" aria-hidden="true" tabindex="-1"></a>cmap <span class="op">=</span> LinearSegmentedColormap.from_list(<span class="st">'custom_cmap'</span>, colors)</span>
<span id="cb94-6"><a href="#cb94-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-7"><a href="#cb94-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Determine the range of residuals to be used for normalization</span></span>
<span id="cb94-8"><a href="#cb94-8" aria-hidden="true" tabindex="-1"></a>residuals_max <span class="op">=</span> <span class="bu">max</span>(<span class="bu">abs</span>(merged_gdf[<span class="st">'residuals_exo'</span>].<span class="bu">max</span>()), <span class="bu">abs</span>(merged_gdf[<span class="st">'residuals'</span>].<span class="bu">max</span>()))</span>
<span id="cb94-9"><a href="#cb94-9" aria-hidden="true" tabindex="-1"></a>vmax <span class="op">=</span> residuals_max <span class="op">*</span> <span class="fl">0.75</span>  <span class="co"># Adjust the factor as needed</span></span>
<span id="cb94-10"><a href="#cb94-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-11"><a href="#cb94-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a normalization object</span></span>
<span id="cb94-12"><a href="#cb94-12" aria-hidden="true" tabindex="-1"></a>norm <span class="op">=</span> Normalize(vmin<span class="op">=-</span>vmax, vmax<span class="op">=</span>vmax)</span>
<span id="cb94-13"><a href="#cb94-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-14"><a href="#cb94-14" aria-hidden="true" tabindex="-1"></a><span class="co"># First graph</span></span>
<span id="cb94-15"><a href="#cb94-15" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">10</span>))  <span class="co"># Create a figure with 1 row and 2 columns</span></span>
<span id="cb94-16"><a href="#cb94-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-17"><a href="#cb94-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Graph 1 - Exogenous variables</span></span>
<span id="cb94-18"><a href="#cb94-18" aria-hidden="true" tabindex="-1"></a>merged_gdf.plot(column<span class="op">=</span><span class="st">'residuals_exo'</span>, cmap<span class="op">=</span>cmap, legend<span class="op">=</span><span class="va">True</span>, ax<span class="op">=</span>axes[<span class="dv">0</span>], vmax<span class="op">=</span>vmax, norm<span class="op">=</span>norm)</span>
<span id="cb94-19"><a href="#cb94-19" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'Spatial Distribution of Residuals (Exogenous)'</span>)</span>
<span id="cb94-20"><a href="#cb94-20" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'Longitude'</span>)</span>
<span id="cb94-21"><a href="#cb94-21" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'Latitude'</span>)</span>
<span id="cb94-22"><a href="#cb94-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-23"><a href="#cb94-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Graph 2 - Spatial lag of PopDensity</span></span>
<span id="cb94-24"><a href="#cb94-24" aria-hidden="true" tabindex="-1"></a>merged_gdf.plot(column<span class="op">=</span><span class="st">'residuals'</span>, cmap<span class="op">=</span>cmap, legend<span class="op">=</span><span class="va">True</span>, ax<span class="op">=</span>axes[<span class="dv">1</span>], vmax<span class="op">=</span>vmax, norm<span class="op">=</span>norm)</span>
<span id="cb94-25"><a href="#cb94-25" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'Spatial Distribution of Residuals (Endogenous)'</span>)</span>
<span id="cb94-26"><a href="#cb94-26" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Longitude'</span>)</span>
<span id="cb94-27"><a href="#cb94-27" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">'Latitude'</span>)</span>
<span id="cb94-28"><a href="#cb94-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-29"><a href="#cb94-29" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="final_project_files/figure-html/cell-57-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-119" class="cell" data-execution_count="61">
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a>num_bins <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a>hist_range <span class="op">=</span> (<span class="dv">0</span>, <span class="dv">2000</span>)</span>
<span id="cb95-3"><a href="#cb95-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-4"><a href="#cb95-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create subplots with two columns</span></span>
<span id="cb95-5"><a href="#cb95-5" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb95-6"><a href="#cb95-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-7"><a href="#cb95-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the first histogram</span></span>
<span id="cb95-8"><a href="#cb95-8" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].hist(merged_gdf[<span class="st">'residuals_exo'</span>], bins<span class="op">=</span>num_bins, <span class="bu">range</span><span class="op">=</span>hist_range, color<span class="op">=</span><span class="st">'green'</span>)</span>
<span id="cb95-9"><a href="#cb95-9" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].set_xlabel(<span class="st">'Absolute Residual'</span>)</span>
<span id="cb95-10"><a href="#cb95-10" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].set_ylabel(<span class="st">'Number of Rows'</span>)</span>
<span id="cb95-11"><a href="#cb95-11" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].set_title(<span class="st">'Distribution of Absolute Residuals (exogenous)'</span>)</span>
<span id="cb95-12"><a href="#cb95-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-13"><a href="#cb95-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the second histogram</span></span>
<span id="cb95-14"><a href="#cb95-14" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].hist(merged_gdf[<span class="st">'residuals'</span>], bins<span class="op">=</span>num_bins, <span class="bu">range</span><span class="op">=</span>hist_range, color<span class="op">=</span><span class="st">'green'</span>)</span>
<span id="cb95-15"><a href="#cb95-15" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].set_xlabel(<span class="st">'Absolute Residual'</span>)</span>
<span id="cb95-16"><a href="#cb95-16" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].set_ylabel(<span class="st">'Number of Rows'</span>)</span>
<span id="cb95-17"><a href="#cb95-17" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].set_title(<span class="st">'Distribution of Absolute Residuals (endogenous)'</span>)</span>
<span id="cb95-18"><a href="#cb95-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-19"><a href="#cb95-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Adjust layout</span></span>
<span id="cb95-20"><a href="#cb95-20" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb95-21"><a href="#cb95-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-22"><a href="#cb95-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Show plots</span></span>
<span id="cb95-23"><a href="#cb95-23" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="final_project_files/figure-html/cell-58-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The exogenous spatial lag residual map is on the left and the endogenous spatial lag residual map is on the right. Qualitatively assessing the these two maps, we see both models tend to underestimate the population density in urban areas. It is reasonable as land cover data is only two dimensional and does not account for the vertical height of the buildings. We also see slightly differences in prediction of rural areas between Exogenous and Endogenous. Endogenous is more accurate in rural areas as the landcover is not a sole factor of prediction, and it instead takes into account the population density of the tracts around it. Exogenous is slightly more inaccurate in these regions for the lack of this parameter. Both models tend to have a better performance at predicting density in less populated areas (Low-Low tracts).</p>
<p>Continuing to explore, we created two residual histograms. We noted that they are similar to our map of CT and do not present any new pattern.</p>
<p>To explore a bit deeper into our dataset, we will look at a snapshot of our map around Hartford and its neighboring cities.</p>
<div id="cell-122" class="cell" data-execution_count="62">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a normalization object</span></span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a>norm <span class="op">=</span> Normalize(vmin<span class="op">=-</span><span class="dv">2000</span>, vmax<span class="op">=</span><span class="dv">2000</span>)</span>
<span id="cb96-3"><a href="#cb96-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-4"><a href="#cb96-4" aria-hidden="true" tabindex="-1"></a><span class="co"># First graph</span></span>
<span id="cb96-5"><a href="#cb96-5" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">10</span>))  <span class="co"># Create a figure with 1 row and 2 columns</span></span>
<span id="cb96-6"><a href="#cb96-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-7"><a href="#cb96-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Graph 2 - Exogenous variables</span></span>
<span id="cb96-8"><a href="#cb96-8" aria-hidden="true" tabindex="-1"></a>merged_gdf.plot(column<span class="op">=</span><span class="st">'residuals_exo'</span>, cmap<span class="op">=</span>cmap, legend<span class="op">=</span><span class="va">True</span>, ax<span class="op">=</span>axes[<span class="dv">0</span>], vmax<span class="op">=</span>vmax, norm<span class="op">=</span>norm)</span>
<span id="cb96-9"><a href="#cb96-9" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'Spatial Distribution of Residuals Near Hartford (Exogenous)'</span>)</span>
<span id="cb96-10"><a href="#cb96-10" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'Longitude'</span>)</span>
<span id="cb96-11"><a href="#cb96-11" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'Latitude'</span>)</span>
<span id="cb96-12"><a href="#cb96-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-13"><a href="#cb96-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Graph 1 - Spatial lag of PopDensity</span></span>
<span id="cb96-14"><a href="#cb96-14" aria-hidden="true" tabindex="-1"></a>merged_gdf.plot(column<span class="op">=</span><span class="st">'residuals'</span>, cmap<span class="op">=</span>cmap, legend<span class="op">=</span><span class="va">True</span>, ax<span class="op">=</span>axes[<span class="dv">1</span>], vmax<span class="op">=</span>vmax, norm<span class="op">=</span>norm)</span>
<span id="cb96-15"><a href="#cb96-15" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'Spatial Distribution of Residuals Near Hartford (Endogenous)'</span>)</span>
<span id="cb96-16"><a href="#cb96-16" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Longitude'</span>)</span>
<span id="cb96-17"><a href="#cb96-17" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">'Latitude'</span>)</span>
<span id="cb96-18"><a href="#cb96-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-19"><a href="#cb96-19" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylim([<span class="fl">41.6</span>, <span class="fl">41.8</span>])</span>
<span id="cb96-20"><a href="#cb96-20" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlim([<span class="op">-</span><span class="fl">72.9</span>, <span class="op">-</span><span class="fl">72.5</span>])</span>
<span id="cb96-21"><a href="#cb96-21" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylim([<span class="fl">41.6</span>, <span class="fl">41.8</span>])</span>
<span id="cb96-22"><a href="#cb96-22" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlim([<span class="op">-</span><span class="fl">72.9</span>, <span class="op">-</span><span class="fl">72.5</span>])</span>
<span id="cb96-23"><a href="#cb96-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-24"><a href="#cb96-24" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="final_project_files/figure-html/cell-59-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>One area we were particularly curious about was Hartford as it is a large urban hub in the central of Connecticut. We noticed that we were grossly underestimating densely populated areas, which makes sense as they are relatively large outliers from the rest of the relatively lower population and spread out suburban areas of Connecticut. However, we were better at calculating more densely populated areas with the Endogenous model. We hypothesize this is due to the fact that Endogenous Models inherently take into account the population densities of neighboring tracts. Thus, there is a greater likelihood that the model will “self-correct” by knowing the population of its neighbors.</p>
</section>
</section>
<section id="training-and-testing-cross-validation" class="level2">
<h2 class="anchored" data-anchor-id="training-and-testing-cross-validation">Training and Testing Cross Validation</h2>
<p>For training and testing, we need to separate the data into two. Due to the spatial dependence of tracts, we cannot randomly select tracts from the dataset and assign them to either training or testing data because neighboring tracts will not be in the same dataset. Therefore, to minimize the rupture of spatial relations, we decide to separate training and testing data by neighboring <strong>counties</strong> to ensure that all tracts in training and testiing data are countinuous. Later, we perform for loops on each set of training and testing data and calculate their mean RMSE for each training and testing set for both endogenous and exogenous model.</p>
<div id="cell-125" class="cell" data-execution_count="63">
<div class="sourceCode cell-code" id="cb97"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a>merged_csv <span class="op">=</span> pd.read_csv(<span class="st">"../data/merged_gdf.csv"</span>)</span>
<span id="cb97-2"><a href="#cb97-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-3"><a href="#cb97-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the county name from the the Geo_NAME column. </span></span>
<span id="cb97-4"><a href="#cb97-4" aria-hidden="true" tabindex="-1"></a>merged_gdf[<span class="st">'County'</span>] <span class="op">=</span> merged_gdf[<span class="st">'Geo_NAME'</span>].<span class="bu">str</span>.split(<span class="st">','</span>).<span class="bu">str</span>[<span class="dv">1</span>].<span class="bu">str</span>.strip().<span class="bu">str</span>.replace(<span class="st">' '</span>, <span class="st">''</span>)</span>
<span id="cb97-5"><a href="#cb97-5" aria-hidden="true" tabindex="-1"></a>merged_gdf <span class="op">=</span> merged_gdf.dropna(subset<span class="op">=</span>[<span class="st">'County'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-126" class="cell">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Spatially lagged endogenous regressor</span></span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a>odd_counties <span class="op">=</span> [<span class="st">'NewLondonCounty'</span>, <span class="st">'NewHavenCounty'</span>, <span class="st">'LitchfieldCounty'</span>, <span class="st">'TollandCounty'</span>]</span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true" tabindex="-1"></a>even_counties <span class="op">=</span> [<span class="st">'MiddlesexCounty'</span>, <span class="st">'FairfieldCounty'</span>,<span class="st">'HartfordCounty'</span>, <span class="st">'WindhamCounty'</span>]</span>
<span id="cb98-4"><a href="#cb98-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-5"><a href="#cb98-5" aria-hidden="true" tabindex="-1"></a>rmse <span class="op">=</span> []</span>
<span id="cb98-6"><a href="#cb98-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-7"><a href="#cb98-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">4</span>):</span>
<span id="cb98-8"><a href="#cb98-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Splitting training and testing counties</span></span>
<span id="cb98-9"><a href="#cb98-9" aria-hidden="true" tabindex="-1"></a>    train_1 <span class="op">=</span> merged_gdf[(merged_gdf[<span class="st">'County'</span>] <span class="op">!=</span> odd_counties[i]) <span class="op">&amp;</span> (merged_gdf[<span class="st">'County'</span>] <span class="op">!=</span> even_counties[i])]</span>
<span id="cb98-10"><a href="#cb98-10" aria-hidden="true" tabindex="-1"></a>    test_1 <span class="op">=</span> merged_gdf[(merged_gdf[<span class="st">'County'</span>] <span class="op">==</span> odd_counties[i]) <span class="op">|</span> (merged_gdf[<span class="st">'County'</span>] <span class="op">==</span> even_counties[i])]</span>
<span id="cb98-11"><a href="#cb98-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-12"><a href="#cb98-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Queen weight matrix for each train and test</span></span>
<span id="cb98-13"><a href="#cb98-13" aria-hidden="true" tabindex="-1"></a>    train_1_w <span class="op">=</span> lp.weights.Queen.from_dataframe(train_1)</span>
<span id="cb98-14"><a href="#cb98-14" aria-hidden="true" tabindex="-1"></a>    test_1_w <span class="op">=</span> lp.weights.Queen.from_dataframe(test_1)</span>
<span id="cb98-15"><a href="#cb98-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb98-16"><a href="#cb98-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Regularize the weights</span></span>
<span id="cb98-17"><a href="#cb98-17" aria-hidden="true" tabindex="-1"></a>    train_1_w.transform <span class="op">=</span> <span class="st">'R'</span></span>
<span id="cb98-18"><a href="#cb98-18" aria-hidden="true" tabindex="-1"></a>    test_1_w.transform <span class="op">=</span> <span class="st">'R'</span></span>
<span id="cb98-19"><a href="#cb98-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb98-20"><a href="#cb98-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate the spatial lag pop density</span></span>
<span id="cb98-21"><a href="#cb98-21" aria-hidden="true" tabindex="-1"></a>    train_1[<span class="st">'spatial_lag_PopDens'</span>] <span class="op">=</span> lp.weights.lag_spatial(train_1_w, train_1[<span class="st">'PopDensity'</span>])</span>
<span id="cb98-22"><a href="#cb98-22" aria-hidden="true" tabindex="-1"></a>    test_1[<span class="st">'spatial_lag_PopDens'</span>] <span class="op">=</span> lp.weights.lag_spatial(test_1_w, test_1[<span class="st">'PopDensity'</span>])</span>
<span id="cb98-23"><a href="#cb98-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb98-24"><a href="#cb98-24" aria-hidden="true" tabindex="-1"></a>    y_train <span class="op">=</span> np.array(train_1[<span class="st">'PopDensity'</span>]).reshape((<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb98-25"><a href="#cb98-25" aria-hidden="true" tabindex="-1"></a>    x_train <span class="op">=</span> np.array(train_1[predictor])</span>
<span id="cb98-26"><a href="#cb98-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-27"><a href="#cb98-27" aria-hidden="true" tabindex="-1"></a>    y_test <span class="op">=</span> np.array(test_1[<span class="st">'PopDensity'</span>])</span>
<span id="cb98-28"><a href="#cb98-28" aria-hidden="true" tabindex="-1"></a>    x_test <span class="op">=</span> np.array(test_1[predictor])</span>
<span id="cb98-29"><a href="#cb98-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-30"><a href="#cb98-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fit linear regression model using scikit-learn </span></span>
<span id="cb98-31"><a href="#cb98-31" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> LinearRegression()</span>
<span id="cb98-32"><a href="#cb98-32" aria-hidden="true" tabindex="-1"></a>    model.fit(x_train, y_train)</span>
<span id="cb98-33"><a href="#cb98-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-34"><a href="#cb98-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Predict on test data</span></span>
<span id="cb98-35"><a href="#cb98-35" aria-hidden="true" tabindex="-1"></a>    y_pred_test <span class="op">=</span> model.predict(x_test)</span>
<span id="cb98-36"><a href="#cb98-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-37"><a href="#cb98-37" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate RMSE</span></span>
<span id="cb98-38"><a href="#cb98-38" aria-hidden="true" tabindex="-1"></a>    test_rmse <span class="op">=</span> np.sqrt(mean_squared_error(y_test, y_pred_test))</span>
<span id="cb98-39"><a href="#cb98-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-40"><a href="#cb98-40" aria-hidden="true" tabindex="-1"></a>    rmse.append(test_rmse)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-127" class="cell" data-execution_count="67">
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a>np.mean(rmse)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="67">
<pre><code>382.27553702535505</code></pre>
</div>
</div>
<p>The average root mean square error of the spatially lagged endogenous regression model is 382.28. The endogenous model is more advantageous when we have a relatively higher coverage of census data and we need to predict the population density of small region surrounded by regions with good census.</p>
<p>Next, we do training and testing cross validation for the exogenous spatial lagged model.</p>
<div id="cell-129" class="cell">
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Spatially lagged exogenous regressors</span></span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-3"><a href="#cb101-3" aria-hidden="true" tabindex="-1"></a>rmse_exo <span class="op">=</span> []</span>
<span id="cb101-4"><a href="#cb101-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-5"><a href="#cb101-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Set loops for each set of different counties</span></span>
<span id="cb101-6"><a href="#cb101-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">4</span>):</span>
<span id="cb101-7"><a href="#cb101-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-8"><a href="#cb101-8" aria-hidden="true" tabindex="-1"></a>    train_1 <span class="op">=</span> merged_gdf[(merged_gdf[<span class="st">'County'</span>] <span class="op">!=</span> odd_counties[i]) <span class="op">&amp;</span> (merged_gdf[<span class="st">'County'</span>] <span class="op">!=</span> even_counties[i])]</span>
<span id="cb101-9"><a href="#cb101-9" aria-hidden="true" tabindex="-1"></a>    test_1 <span class="op">=</span> merged_gdf[(merged_gdf[<span class="st">'County'</span>] <span class="op">==</span> odd_counties[i]) <span class="op">|</span> (merged_gdf[<span class="st">'County'</span>] <span class="op">==</span> even_counties[i])]</span>
<span id="cb101-10"><a href="#cb101-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-11"><a href="#cb101-11" aria-hidden="true" tabindex="-1"></a>    train_1_w <span class="op">=</span> lp.weights.Queen.from_dataframe(train_1)</span>
<span id="cb101-12"><a href="#cb101-12" aria-hidden="true" tabindex="-1"></a>    test_1_w <span class="op">=</span> lp.weights.Queen.from_dataframe(test_1)</span>
<span id="cb101-13"><a href="#cb101-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-14"><a href="#cb101-14" aria-hidden="true" tabindex="-1"></a>    train_1_w.transform <span class="op">=</span> <span class="st">'R'</span></span>
<span id="cb101-15"><a href="#cb101-15" aria-hidden="true" tabindex="-1"></a>    test_1_w.transform <span class="op">=</span> <span class="st">'R'</span></span>
<span id="cb101-16"><a href="#cb101-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-17"><a href="#cb101-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate spatial lag </span></span>
<span id="cb101-18"><a href="#cb101-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(landcover_pct)):</span>
<span id="cb101-19"><a href="#cb101-19" aria-hidden="true" tabindex="-1"></a>        train_1[<span class="st">'lag_'</span> <span class="op">+</span> landcover_pct[j]] <span class="op">=</span> lp.weights.lag_spatial(train_1_w, train_1[landcover_pct[j]])</span>
<span id="cb101-20"><a href="#cb101-20" aria-hidden="true" tabindex="-1"></a>        test_1[<span class="st">'lag_'</span> <span class="op">+</span> landcover_pct[j]] <span class="op">=</span> lp.weights.lag_spatial(test_1_w, test_1[landcover_pct[j]])</span>
<span id="cb101-21"><a href="#cb101-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb101-22"><a href="#cb101-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Extract training and test data </span></span>
<span id="cb101-23"><a href="#cb101-23" aria-hidden="true" tabindex="-1"></a>    y_train <span class="op">=</span> np.array(train_1[<span class="st">'PopDensity'</span>]).reshape((<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb101-24"><a href="#cb101-24" aria-hidden="true" tabindex="-1"></a>    x_train <span class="op">=</span> np.array(train_1[exo_predictor])</span>
<span id="cb101-25"><a href="#cb101-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-26"><a href="#cb101-26" aria-hidden="true" tabindex="-1"></a>    y_test <span class="op">=</span> np.array(test_1[<span class="st">'PopDensity'</span>])</span>
<span id="cb101-27"><a href="#cb101-27" aria-hidden="true" tabindex="-1"></a>    x_test <span class="op">=</span> np.array(test_1[exo_predictor])</span>
<span id="cb101-28"><a href="#cb101-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-29"><a href="#cb101-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fit linear regression model using scikit-learn </span></span>
<span id="cb101-30"><a href="#cb101-30" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> LinearRegression()</span>
<span id="cb101-31"><a href="#cb101-31" aria-hidden="true" tabindex="-1"></a>    model.fit(x_train, y_train)</span>
<span id="cb101-32"><a href="#cb101-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-33"><a href="#cb101-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Predict on test data</span></span>
<span id="cb101-34"><a href="#cb101-34" aria-hidden="true" tabindex="-1"></a>    y_pred_test <span class="op">=</span> model.predict(x_test)</span>
<span id="cb101-35"><a href="#cb101-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-36"><a href="#cb101-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate RMSE</span></span>
<span id="cb101-37"><a href="#cb101-37" aria-hidden="true" tabindex="-1"></a>    test_rmse <span class="op">=</span> np.sqrt(mean_squared_error(y_test, y_pred_test))</span>
<span id="cb101-38"><a href="#cb101-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-39"><a href="#cb101-39" aria-hidden="true" tabindex="-1"></a>    rmse_exo.append(test_rmse)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-130" class="cell" data-execution_count="70">
<div class="sourceCode cell-code" id="cb102"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a>np.mean(rmse_exo)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="70">
<pre><code>391.66561692553</code></pre>
</div>
</div>
<p>The average RMSE of the spatially lagged endogenous regression model cross validation is 391.67, which is slightly larger than the RMSE of the endogenous model. The exogenous model is more applicable to scenarios when we have good satellite data but sparse census data.</p>
<p>Comparing our Spatial Autoregression to our Linear regression, it is clear that our Spatial Regression yields better results.</p>
</section>
<section id="concluding-discussion" class="level2">
<h2 class="anchored" data-anchor-id="concluding-discussion">Concluding Discussion</h2>
<p>Through this project, we were able to implement three different forms of Linear Regression, as well as create Spatial Autoregression models, and we determined the efficacy of each of these models both mathematically and graphically. Our results were relatively similar to <span class="citation" data-cites="tian2005modeling">Tian et al. (<a href="#ref-tian2005modeling" role="doc-biblioref">2005</a>)</span> in that they underpredicted the population density in densely populated urban areas more frequently than other plots of land, and over-predicted population density in rural areas. Overall, we accomplished a few key things with project. Through our models, we were able to predict population density with only landcover with relatively strong accuracy. We successfully compared different machine learning models and concluded that Spatial Autoregression was more accurate than Linear Regression. With more time, we would have liked to implement Poisson Regression and performed analysis at the block group level instead of tract level. With more computational power, we would have liked to calculate a larger dataset, representing a larger spatial region. Overall, we are proud of our work!</p>
</section>
<section id="group-contributions-statement" class="level2">
<h2 class="anchored" data-anchor-id="group-contributions-statement">Group Contributions Statement</h2>
<p>Liam helped with data acquisition and preparation, wrote our implementation of linear regression with gradient descent in <a href="https://github.com/Liam-W-Smith/csci-0451-final-project/blob/main/code/linear_regression.py">linear_regression.py</a>, and compared the output of our class with that of scikit-learn. Alex acquired landcover data from Conus, and shapefile data of Connecticut. He then implemented zonal statistics with Manny. Alex explained the differences in Spatial Autoregression methods, trained the models, and utilized cross validation. Manny created visualizations of our models to represent graphically the residuals of each model. He proof-read all of our code, making corrections, rewriting descriptions, and ensuring cohesive and consistent writing styles. He also contributed to code in the Spatial Auto Regression section.</p>
</section>
<section id="personal-reflection" class="level2">
<h2 class="anchored" data-anchor-id="personal-reflection">Personal Reflection</h2>
<p>I learned a lot from this process. From a non-technical standpoint, I was working with two really smart mathematicians who have taken a few computer science classes and it was really cool to learn how they operated. They coded differently, commented differently, and got into different problems than I got into while running code. Through this, i learned how to work with non-computer scientists and we were able to work of their domain-specific knowledge of geography with my more computer-science-oriented expertise to create a well-manicured project. From a technical standpoint, a lot of this project involved understanding GIS and key components of this such as tracts, shapefiles, and zonal statistics. I spent extra time understanding these materials. In addition, I also learned about a different type of machine learning model which called Spatial Autoregression which was super cool. I thought I achieved a good amount, I became much more involved in understanding the theoretical and mathematical aspects of this project. I was not able to implement Poisson Regression, but that was okay as I feel with more time I would have been able to do this.</p>
<p>With the information I have learned in this project, I really want to do a similar project in Taiwan. I am going to be there for the next 18 months working as a English Tutor and also doing some CS internship there and I am really curious about how this would apply to a place like Taiwan, as it is densely covered in forests. I can see myself continuing to explore GIS applications of Computer Science.</p>



</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-liu2022incorporating" class="csl-entry" role="listitem">
Liu, Xiaojian, Ourania Kounadi, and Raul Zurita-Milla. 2022. <span>“Incorporating Spatial Autocorrelation in Machine Learning Models Using Spatial Lag and Eigenvector Spatial Filtering Features.”</span> <em>ISPRS International Journal of Geo-Information</em> 11 (4): 242.
</div>
<div id="ref-tian2005modeling" class="csl-entry" role="listitem">
Tian, Yongzhong, Tianxiang Yue, Lifen Zhu, and Nicholas Clinton. 2005. <span>“Modeling Population Density Using Land Cover Data.”</span> <em>Ecological Modelling</em> 189 (1-2): 72–88.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>